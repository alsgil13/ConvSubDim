{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Softmax\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Reshape, GlobalAveragePooling2D, GlobalAveragePooling1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.initializers import RandomNormal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "num_classes = 10 #pegar automaticamente NumPy.Unique\n",
    "epochs = 200\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Cifar-10 Data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "#Adicionando Canal do DataSet (Channel do MNIST eh 1)\n",
    "x_train = np.reshape(x_train, (len(x_train),28,28, 1))\n",
    "x_test = np.reshape(x_test, (len(x_test),28,28, 1))\n",
    "\n",
    "\n",
    "#x_train.shape\n",
    "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
    "#channel=1\n",
    "\n",
    "x_train.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#\n",
    "x_train.shape\n",
    "\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert to one hot encoing \n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#Filters = IMG_width/2 * 7\n",
    "model.add(Conv2D(98, #alterado de 168 para 98\n",
    "                 (5,5), #alterado de 3 para 5 \n",
    "                 strides=(2,2), \n",
    "                 activation='relu', \n",
    "                 padding='same',\n",
    "                 data_format='channels_last',\n",
    "                 use_bias=True, \n",
    "                 kernel_initializer=RandomNormal(mean=0.0, stddev=0.05, seed=None), \n",
    "                 bias_initializer='zeros',\n",
    "                 input_shape=(img_height, img_width, channel)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), \n",
    "                       strides=(2,2)))\n",
    "\n",
    "#Normalization:\n",
    "#calculo da quantidade de filtros da normalização:\n",
    "# Width*heigth da saída após a primeira camada de convolução+pooling\n",
    "model.add(Conv2D(49, \n",
    "                 (1,1), \n",
    "                 strides=(1,1), \n",
    "                 activation='relu', \n",
    "                 padding='same',\n",
    "                 kernel_initializer=RandomNormal(mean=0.0, stddev=0.05, seed=None), \n",
    "                 data_format='channels_last'))\n",
    "model.add(Conv2D(49, \n",
    "                 (1,1), \n",
    "                 strides=(1,1), \n",
    "                 activation='relu', \n",
    "                 padding='same',\n",
    "                 kernel_initializer=RandomNormal(mean=0.0, stddev=0.05, seed=None),                  \n",
    "                 data_format='channels_last'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#Filters = IMG_width/2 * 9\n",
    "model.add(Conv2D(126, \n",
    "                 (5,5), \n",
    "                 strides=(2,2), \n",
    "                 activation='relu', \n",
    "                 padding='same',\n",
    "                 data_format='channels_last',\n",
    "                 use_bias=True, \n",
    "                 kernel_initializer=RandomNormal(mean=0.0, stddev=0.05, seed=None), \n",
    "                 bias_initializer='zeros',\n",
    "                 input_shape=(img_height, img_width, channel)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), \n",
    "                       strides=(2,2)))\n",
    "#Normalization:\n",
    "#calculo da quantidade de filtros da normalização:\n",
    "# Width*heigth da saída após a primeira camada de convolução+pooling\n",
    "model.add(Conv2D(49, \n",
    "                 (1,1), \n",
    "                 strides=(1,1), \n",
    "                 activation='relu', \n",
    "                 padding='same',\n",
    "                 kernel_initializer=RandomNormal(mean=0.0, stddev=0.05, seed=None),                  \n",
    "                 data_format='channels_last'))\n",
    "model.add(Conv2D(49, \n",
    "                 (1,1), \n",
    "                 strides=(1,1), \n",
    "                 activation='relu', \n",
    "                 padding='same',\n",
    "                 kernel_initializer=RandomNormal(mean=0.0, stddev=0.05, seed=None),                  \n",
    "                 data_format='channels_last'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "#IMG_width^ 2\n",
    "model.add(Dense(784, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#camada anterior/2\n",
    "model.add(Dense(392, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#Num de classes\n",
    "model.add(Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 98)        2548      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 98)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 49)          4851      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 49)          2450      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 49)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 126)         154476    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 126)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 2, 2, 49)          6223      \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 2, 2, 49)          2450      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2, 2, 49)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 784)               154448    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 392)               307720    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 392)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                3930      \n",
      "=================================================================\n",
      "Total params: 639,096\n",
      "Trainable params: 639,096\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print the model summary\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# determine Loss function and Optimizer\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=0.01, momentum=0.02, decay=0.0, nesterov=False),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "60000/60000 [==============================] - 55s 910us/step - loss: 2.0327 - acc: 0.2452 - val_loss: 0.7797 - val_acc: 0.7280\n",
      "Epoch 2/200\n",
      "60000/60000 [==============================] - 54s 898us/step - loss: 0.8204 - acc: 0.7251 - val_loss: 0.2626 - val_acc: 0.9240\n",
      "Epoch 3/200\n",
      "60000/60000 [==============================] - 54s 902us/step - loss: 0.4543 - acc: 0.8622 - val_loss: 0.2007 - val_acc: 0.9398\n",
      "Epoch 4/200\n",
      "60000/60000 [==============================] - 54s 892us/step - loss: 0.3373 - acc: 0.9022 - val_loss: 0.1194 - val_acc: 0.9617\n",
      "Epoch 5/200\n",
      "60000/60000 [==============================] - 53s 891us/step - loss: 0.2738 - acc: 0.9213 - val_loss: 0.1160 - val_acc: 0.9668\n",
      "Epoch 6/200\n",
      "60000/60000 [==============================] - 54s 899us/step - loss: 0.2406 - acc: 0.9315 - val_loss: 0.0814 - val_acc: 0.9746\n",
      "Epoch 7/200\n",
      "60000/60000 [==============================] - 54s 900us/step - loss: 0.2186 - acc: 0.9390 - val_loss: 0.0786 - val_acc: 0.9745\n",
      "Epoch 8/200\n",
      "60000/60000 [==============================] - 54s 893us/step - loss: 0.1948 - acc: 0.9446 - val_loss: 0.0745 - val_acc: 0.9762\n",
      "Epoch 9/200\n",
      "60000/60000 [==============================] - 54s 893us/step - loss: 0.1770 - acc: 0.9499 - val_loss: 0.0653 - val_acc: 0.9787\n",
      "Epoch 10/200\n",
      "60000/60000 [==============================] - 54s 895us/step - loss: 0.1669 - acc: 0.9530 - val_loss: 0.0625 - val_acc: 0.9800\n",
      "Epoch 11/200\n",
      "60000/60000 [==============================] - 54s 903us/step - loss: 0.1555 - acc: 0.9566 - val_loss: 0.0552 - val_acc: 0.9823\n",
      "Epoch 12/200\n",
      "60000/60000 [==============================] - 54s 900us/step - loss: 0.1484 - acc: 0.9577 - val_loss: 0.0557 - val_acc: 0.9824\n",
      "Epoch 13/200\n",
      "60000/60000 [==============================] - 54s 900us/step - loss: 0.1411 - acc: 0.9606 - val_loss: 0.0504 - val_acc: 0.9834\n",
      "Epoch 14/200\n",
      "60000/60000 [==============================] - 54s 899us/step - loss: 0.1377 - acc: 0.9624 - val_loss: 0.0462 - val_acc: 0.9851\n",
      "Epoch 15/200\n",
      "60000/60000 [==============================] - 54s 899us/step - loss: 0.1291 - acc: 0.9646 - val_loss: 0.0456 - val_acc: 0.9847\n",
      "Epoch 16/200\n",
      "60000/60000 [==============================] - 54s 898us/step - loss: 0.1244 - acc: 0.9655 - val_loss: 0.0480 - val_acc: 0.9854\n",
      "Epoch 17/200\n",
      "60000/60000 [==============================] - 54s 897us/step - loss: 0.1204 - acc: 0.9666 - val_loss: 0.0425 - val_acc: 0.9868\n",
      "Epoch 18/200\n",
      "60000/60000 [==============================] - 54s 899us/step - loss: 0.1169 - acc: 0.9679 - val_loss: 0.0403 - val_acc: 0.9876\n",
      "Epoch 19/200\n",
      "60000/60000 [==============================] - 54s 900us/step - loss: 0.1082 - acc: 0.9702 - val_loss: 0.0417 - val_acc: 0.9867\n",
      "Epoch 20/200\n",
      "60000/60000 [==============================] - 54s 895us/step - loss: 0.1081 - acc: 0.9705 - val_loss: 0.0542 - val_acc: 0.9823\n",
      "Epoch 21/200\n",
      "60000/60000 [==============================] - 54s 898us/step - loss: 0.1049 - acc: 0.9711 - val_loss: 0.0388 - val_acc: 0.9875\n",
      "Epoch 22/200\n",
      "60000/60000 [==============================] - 54s 900us/step - loss: 0.0989 - acc: 0.9726 - val_loss: 0.0520 - val_acc: 0.9846\n",
      "Epoch 23/200\n",
      "60000/60000 [==============================] - 54s 902us/step - loss: 0.0979 - acc: 0.9725 - val_loss: 0.0410 - val_acc: 0.9871\n",
      "Epoch 24/200\n",
      "60000/60000 [==============================] - 54s 901us/step - loss: 0.0965 - acc: 0.9733 - val_loss: 0.0340 - val_acc: 0.9895\n",
      "Epoch 25/200\n",
      "60000/60000 [==============================] - 54s 902us/step - loss: 0.0924 - acc: 0.9742 - val_loss: 0.0338 - val_acc: 0.9891\n",
      "Epoch 26/200\n",
      "60000/60000 [==============================] - 54s 903us/step - loss: 0.0921 - acc: 0.9742 - val_loss: 0.0351 - val_acc: 0.9895\n",
      "Epoch 27/200\n",
      "60000/60000 [==============================] - 54s 904us/step - loss: 0.0903 - acc: 0.9748 - val_loss: 0.2428 - val_acc: 0.9376\n",
      "Epoch 28/200\n",
      "60000/60000 [==============================] - 54s 904us/step - loss: 0.0872 - acc: 0.9753 - val_loss: 0.0320 - val_acc: 0.9901\n",
      "Epoch 29/200\n",
      "60000/60000 [==============================] - 54s 902us/step - loss: 0.0881 - acc: 0.9758 - val_loss: 0.0367 - val_acc: 0.9878\n",
      "Epoch 30/200\n",
      "60000/60000 [==============================] - 54s 896us/step - loss: 0.0842 - acc: 0.9757 - val_loss: 0.0336 - val_acc: 0.9896\n",
      "Epoch 31/200\n",
      "60000/60000 [==============================] - 54s 900us/step - loss: 0.0825 - acc: 0.9770 - val_loss: 0.0315 - val_acc: 0.9902\n",
      "Epoch 32/200\n",
      "60000/60000 [==============================] - 54s 900us/step - loss: 0.0805 - acc: 0.9775 - val_loss: 0.0329 - val_acc: 0.9892\n",
      "Epoch 33/200\n",
      "60000/60000 [==============================] - 54s 907us/step - loss: 0.0786 - acc: 0.9782 - val_loss: 0.0343 - val_acc: 0.9895\n",
      "Epoch 34/200\n",
      "60000/60000 [==============================] - 54s 899us/step - loss: 0.0770 - acc: 0.9788 - val_loss: 0.0316 - val_acc: 0.9896\n",
      "Epoch 35/200\n",
      "60000/60000 [==============================] - 54s 902us/step - loss: 0.0799 - acc: 0.9783 - val_loss: 0.0295 - val_acc: 0.9904\n",
      "Epoch 36/200\n",
      "60000/60000 [==============================] - 54s 901us/step - loss: 0.0776 - acc: 0.9784 - val_loss: 0.0292 - val_acc: 0.9904\n",
      "Epoch 37/200\n",
      "60000/60000 [==============================] - 54s 905us/step - loss: 0.0733 - acc: 0.9789 - val_loss: 0.0316 - val_acc: 0.9910\n",
      "Epoch 38/200\n",
      "60000/60000 [==============================] - 54s 903us/step - loss: 0.0706 - acc: 0.9798 - val_loss: 0.0277 - val_acc: 0.9905\n",
      "Epoch 39/200\n",
      "60000/60000 [==============================] - 54s 906us/step - loss: 0.0714 - acc: 0.9801 - val_loss: 0.0271 - val_acc: 0.9905\n",
      "Epoch 40/200\n",
      "60000/60000 [==============================] - 54s 903us/step - loss: 0.0705 - acc: 0.9802 - val_loss: 0.0310 - val_acc: 0.9901\n",
      "Epoch 41/200\n",
      "60000/60000 [==============================] - 54s 896us/step - loss: 0.0702 - acc: 0.9807 - val_loss: 0.0306 - val_acc: 0.9897\n",
      "Epoch 42/200\n",
      "60000/60000 [==============================] - 54s 904us/step - loss: 0.0679 - acc: 0.9809 - val_loss: 0.0259 - val_acc: 0.9913\n",
      "Epoch 43/200\n",
      "60000/60000 [==============================] - 54s 903us/step - loss: 0.0681 - acc: 0.9810 - val_loss: 0.0268 - val_acc: 0.9911\n",
      "Epoch 44/200\n",
      "60000/60000 [==============================] - 54s 905us/step - loss: 0.0661 - acc: 0.9812 - val_loss: 0.0276 - val_acc: 0.9911\n",
      "Epoch 45/200\n",
      "60000/60000 [==============================] - 54s 902us/step - loss: 0.0664 - acc: 0.9810 - val_loss: 0.0257 - val_acc: 0.9914\n",
      "Epoch 46/200\n",
      "60000/60000 [==============================] - 54s 902us/step - loss: 0.0657 - acc: 0.9813 - val_loss: 0.0272 - val_acc: 0.9905\n",
      "Epoch 47/200\n",
      "60000/60000 [==============================] - 54s 897us/step - loss: 0.0602 - acc: 0.9828 - val_loss: 0.0276 - val_acc: 0.9899\n",
      "Epoch 48/200\n",
      "60000/60000 [==============================] - 54s 896us/step - loss: 0.0620 - acc: 0.9823 - val_loss: 0.0285 - val_acc: 0.9899\n",
      "Epoch 49/200\n",
      "60000/60000 [==============================] - 54s 903us/step - loss: 0.0612 - acc: 0.9825 - val_loss: 0.0279 - val_acc: 0.9910\n",
      "Epoch 50/200\n",
      "60000/60000 [==============================] - 54s 906us/step - loss: 0.0616 - acc: 0.9828 - val_loss: 0.0266 - val_acc: 0.9913\n",
      "Epoch 51/200\n",
      "60000/60000 [==============================] - 46s 775us/step - loss: 0.0591 - acc: 0.9837 - val_loss: 0.0287 - val_acc: 0.9910\n",
      "Epoch 52/200\n",
      "60000/60000 [==============================] - 53s 882us/step - loss: 0.0599 - acc: 0.9832 - val_loss: 0.0258 - val_acc: 0.9919\n",
      "Epoch 53/200\n",
      "60000/60000 [==============================] - 54s 902us/step - loss: 0.0554 - acc: 0.9840 - val_loss: 0.0247 - val_acc: 0.9918\n",
      "Epoch 54/200\n",
      "60000/60000 [==============================] - 54s 901us/step - loss: 0.0589 - acc: 0.9833 - val_loss: 0.0302 - val_acc: 0.9909\n",
      "Epoch 55/200\n",
      "60000/60000 [==============================] - 54s 899us/step - loss: 0.0561 - acc: 0.9838 - val_loss: 0.0249 - val_acc: 0.9912\n",
      "Epoch 56/200\n",
      "60000/60000 [==============================] - 54s 898us/step - loss: 0.0563 - acc: 0.9841 - val_loss: 0.0273 - val_acc: 0.9906\n",
      "Epoch 57/200\n",
      "60000/60000 [==============================] - 54s 896us/step - loss: 0.0540 - acc: 0.9850 - val_loss: 0.0258 - val_acc: 0.9918\n",
      "Epoch 58/200\n",
      "60000/60000 [==============================] - 54s 896us/step - loss: 0.0542 - acc: 0.9848 - val_loss: 0.0278 - val_acc: 0.9903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "60000/60000 [==============================] - 54s 896us/step - loss: 0.0554 - acc: 0.9841 - val_loss: 0.0270 - val_acc: 0.9913\n",
      "Epoch 60/200\n",
      "60000/60000 [==============================] - 54s 894us/step - loss: 0.0562 - acc: 0.9843 - val_loss: 0.0279 - val_acc: 0.9914\n",
      "Epoch 61/200\n",
      "60000/60000 [==============================] - 53s 892us/step - loss: 0.0531 - acc: 0.9849 - val_loss: 0.0262 - val_acc: 0.9915\n",
      "Epoch 62/200\n",
      "60000/60000 [==============================] - 54s 896us/step - loss: 0.0539 - acc: 0.9844 - val_loss: 0.0226 - val_acc: 0.9922\n",
      "Epoch 63/200\n",
      "60000/60000 [==============================] - 54s 899us/step - loss: 0.0541 - acc: 0.9846 - val_loss: 0.0255 - val_acc: 0.9922\n",
      "Epoch 64/200\n",
      "60000/60000 [==============================] - 54s 901us/step - loss: 0.0512 - acc: 0.9853 - val_loss: 0.0241 - val_acc: 0.9921\n",
      "Epoch 65/200\n",
      "60000/60000 [==============================] - 54s 907us/step - loss: 0.0507 - acc: 0.9853 - val_loss: 0.0276 - val_acc: 0.9906\n",
      "Epoch 66/200\n",
      "60000/60000 [==============================] - 55s 908us/step - loss: 0.0501 - acc: 0.9864 - val_loss: 0.0284 - val_acc: 0.9914\n",
      "Epoch 67/200\n",
      "60000/60000 [==============================] - 54s 902us/step - loss: 0.0510 - acc: 0.9853 - val_loss: 0.0230 - val_acc: 0.9924\n",
      "Epoch 68/200\n",
      "60000/60000 [==============================] - 54s 905us/step - loss: 0.0498 - acc: 0.9866 - val_loss: 0.0279 - val_acc: 0.9909\n",
      "Epoch 69/200\n",
      "60000/60000 [==============================] - 54s 900us/step - loss: 0.0497 - acc: 0.9863 - val_loss: 0.0298 - val_acc: 0.9915\n",
      "Epoch 70/200\n",
      "60000/60000 [==============================] - 54s 900us/step - loss: 0.0508 - acc: 0.9858 - val_loss: 0.0244 - val_acc: 0.9925\n",
      "Epoch 71/200\n",
      "60000/60000 [==============================] - 54s 901us/step - loss: 0.0497 - acc: 0.9863 - val_loss: 0.0225 - val_acc: 0.9920\n",
      "Epoch 72/200\n",
      "60000/60000 [==============================] - 54s 903us/step - loss: 0.0475 - acc: 0.9868 - val_loss: 0.0245 - val_acc: 0.9924\n",
      "Epoch 73/200\n",
      "60000/60000 [==============================] - 55s 911us/step - loss: 0.0446 - acc: 0.9869 - val_loss: 0.0230 - val_acc: 0.9921\n",
      "Epoch 74/200\n",
      "60000/60000 [==============================] - 54s 906us/step - loss: 0.0470 - acc: 0.9870 - val_loss: 0.0221 - val_acc: 0.9927\n",
      "Epoch 75/200\n",
      "60000/60000 [==============================] - 54s 908us/step - loss: 0.0470 - acc: 0.9867 - val_loss: 0.0240 - val_acc: 0.9921\n",
      "Epoch 76/200\n",
      "60000/60000 [==============================] - 54s 904us/step - loss: 0.0464 - acc: 0.9868 - val_loss: 0.0251 - val_acc: 0.9917\n",
      "Epoch 77/200\n",
      "60000/60000 [==============================] - 54s 904us/step - loss: 0.0483 - acc: 0.9867 - val_loss: 0.0219 - val_acc: 0.9918\n",
      "Epoch 78/200\n",
      "60000/60000 [==============================] - 55s 910us/step - loss: 0.0433 - acc: 0.9879 - val_loss: 0.0216 - val_acc: 0.9927\n",
      "Epoch 79/200\n",
      "60000/60000 [==============================] - 54s 907us/step - loss: 0.0443 - acc: 0.9874 - val_loss: 0.0223 - val_acc: 0.9926\n",
      "Epoch 80/200\n",
      "60000/60000 [==============================] - 54s 904us/step - loss: 0.0435 - acc: 0.9879 - val_loss: 0.0241 - val_acc: 0.9920\n",
      "Epoch 81/200\n",
      "60000/60000 [==============================] - 55s 909us/step - loss: 0.0421 - acc: 0.9882 - val_loss: 0.0213 - val_acc: 0.9928\n",
      "Epoch 82/200\n",
      "60000/60000 [==============================] - 54s 902us/step - loss: 0.0416 - acc: 0.9880 - val_loss: 0.0230 - val_acc: 0.9918\n",
      "Epoch 83/200\n",
      "60000/60000 [==============================] - 54s 901us/step - loss: 0.0411 - acc: 0.9880 - val_loss: 0.0232 - val_acc: 0.9929\n",
      "Epoch 84/200\n",
      "60000/60000 [==============================] - 54s 907us/step - loss: 0.0439 - acc: 0.9871 - val_loss: 0.0219 - val_acc: 0.9934\n",
      "Epoch 85/200\n",
      "60000/60000 [==============================] - 54s 906us/step - loss: 0.0427 - acc: 0.9883 - val_loss: 0.0224 - val_acc: 0.9921\n",
      "Epoch 86/200\n",
      "60000/60000 [==============================] - 54s 903us/step - loss: 0.0413 - acc: 0.9888 - val_loss: 0.0238 - val_acc: 0.9927\n",
      "Epoch 87/200\n",
      "60000/60000 [==============================] - 54s 908us/step - loss: 0.0421 - acc: 0.9879 - val_loss: 0.0220 - val_acc: 0.9928\n",
      "Epoch 88/200\n",
      "60000/60000 [==============================] - 54s 908us/step - loss: 0.0404 - acc: 0.9888 - val_loss: 0.0286 - val_acc: 0.9906\n",
      "Epoch 89/200\n",
      "60000/60000 [==============================] - 55s 912us/step - loss: 0.0393 - acc: 0.9886 - val_loss: 0.0230 - val_acc: 0.9930\n",
      "Epoch 90/200\n",
      "60000/60000 [==============================] - 54s 906us/step - loss: 0.0421 - acc: 0.9880 - val_loss: 0.0214 - val_acc: 0.9931\n",
      "Epoch 91/200\n",
      "60000/60000 [==============================] - 55s 912us/step - loss: 0.0419 - acc: 0.9880 - val_loss: 0.0220 - val_acc: 0.9926\n",
      "Epoch 92/200\n",
      "60000/60000 [==============================] - 55s 911us/step - loss: 0.0383 - acc: 0.9886 - val_loss: 0.0219 - val_acc: 0.9927\n",
      "Epoch 93/200\n",
      "60000/60000 [==============================] - 54s 907us/step - loss: 0.0414 - acc: 0.9880 - val_loss: 0.0218 - val_acc: 0.9923\n",
      "Epoch 94/200\n",
      "60000/60000 [==============================] - 55s 910us/step - loss: 0.0399 - acc: 0.9886 - val_loss: 0.0222 - val_acc: 0.9926\n",
      "Epoch 95/200\n",
      "60000/60000 [==============================] - 54s 908us/step - loss: 0.0376 - acc: 0.9893 - val_loss: 0.0237 - val_acc: 0.9932\n",
      "Epoch 96/200\n",
      "60000/60000 [==============================] - 54s 905us/step - loss: 0.0391 - acc: 0.9882 - val_loss: 0.0221 - val_acc: 0.9930\n",
      "Epoch 97/200\n",
      "60000/60000 [==============================] - 55s 908us/step - loss: 0.0385 - acc: 0.9888 - val_loss: 0.0227 - val_acc: 0.9928\n",
      "Epoch 98/200\n",
      "60000/60000 [==============================] - 55s 913us/step - loss: 0.0357 - acc: 0.9888 - val_loss: 0.0238 - val_acc: 0.9930\n",
      "Epoch 99/200\n",
      "60000/60000 [==============================] - 55s 913us/step - loss: 0.0357 - acc: 0.9895 - val_loss: 0.0262 - val_acc: 0.9925\n",
      "Epoch 100/200\n",
      "60000/60000 [==============================] - 54s 907us/step - loss: 0.0385 - acc: 0.9892 - val_loss: 0.0228 - val_acc: 0.9919\n",
      "Epoch 101/200\n",
      "60000/60000 [==============================] - 54s 904us/step - loss: 0.0357 - acc: 0.9898 - val_loss: 0.0229 - val_acc: 0.9927\n",
      "Epoch 102/200\n",
      "60000/60000 [==============================] - 54s 903us/step - loss: 0.0378 - acc: 0.9887 - val_loss: 0.0231 - val_acc: 0.9921\n",
      "Epoch 103/200\n",
      "60000/60000 [==============================] - 54s 907us/step - loss: 0.0388 - acc: 0.9889 - val_loss: 0.0228 - val_acc: 0.9929\n",
      "Epoch 104/200\n",
      "60000/60000 [==============================] - 54s 900us/step - loss: 0.0353 - acc: 0.9894 - val_loss: 0.0221 - val_acc: 0.9930\n",
      "Epoch 105/200\n",
      "60000/60000 [==============================] - 55s 912us/step - loss: 0.0369 - acc: 0.9890 - val_loss: 0.0205 - val_acc: 0.9925\n",
      "Epoch 106/200\n",
      "60000/60000 [==============================] - 54s 905us/step - loss: 0.0354 - acc: 0.9899 - val_loss: 0.0200 - val_acc: 0.9932\n",
      "Epoch 107/200\n",
      "60000/60000 [==============================] - 55s 910us/step - loss: 0.0341 - acc: 0.9897 - val_loss: 0.0215 - val_acc: 0.9924\n",
      "Epoch 108/200\n",
      "60000/60000 [==============================] - 54s 904us/step - loss: 0.0358 - acc: 0.9901 - val_loss: 0.0215 - val_acc: 0.9924\n",
      "Epoch 109/200\n",
      "60000/60000 [==============================] - 54s 901us/step - loss: 0.0339 - acc: 0.9903 - val_loss: 0.0216 - val_acc: 0.9930\n",
      "Epoch 110/200\n",
      "60000/60000 [==============================] - 54s 906us/step - loss: 0.0356 - acc: 0.9897 - val_loss: 0.0219 - val_acc: 0.9938\n",
      "Epoch 111/200\n",
      "60000/60000 [==============================] - 54s 905us/step - loss: 0.0337 - acc: 0.9902 - val_loss: 0.0243 - val_acc: 0.9919\n",
      "Epoch 112/200\n",
      "60000/60000 [==============================] - 54s 902us/step - loss: 0.0356 - acc: 0.9897 - val_loss: 0.0270 - val_acc: 0.9925\n",
      "Epoch 113/200\n",
      "60000/60000 [==============================] - 54s 901us/step - loss: 0.0330 - acc: 0.9907 - val_loss: 0.0215 - val_acc: 0.9931\n",
      "Epoch 114/200\n",
      "60000/60000 [==============================] - 54s 905us/step - loss: 0.0338 - acc: 0.9902 - val_loss: 0.0217 - val_acc: 0.9928\n",
      "Epoch 115/200\n",
      "60000/60000 [==============================] - 54s 902us/step - loss: 0.0333 - acc: 0.9906 - val_loss: 0.0258 - val_acc: 0.9927\n",
      "Epoch 116/200\n",
      "60000/60000 [==============================] - 55s 911us/step - loss: 0.0335 - acc: 0.9904 - val_loss: 0.0222 - val_acc: 0.9920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/200\n",
      "60000/60000 [==============================] - 55s 910us/step - loss: 0.0338 - acc: 0.9902 - val_loss: 0.0218 - val_acc: 0.9931\n",
      "Epoch 118/200\n",
      "60000/60000 [==============================] - 54s 905us/step - loss: 0.0319 - acc: 0.9907 - val_loss: 0.0210 - val_acc: 0.9936\n",
      "Epoch 119/200\n",
      "60000/60000 [==============================] - 55s 909us/step - loss: 0.0329 - acc: 0.9907 - val_loss: 0.0217 - val_acc: 0.9928\n",
      "Epoch 120/200\n",
      "60000/60000 [==============================] - 55s 909us/step - loss: 0.0308 - acc: 0.9913 - val_loss: 0.0214 - val_acc: 0.9925\n",
      "Epoch 121/200\n",
      "60000/60000 [==============================] - 54s 907us/step - loss: 0.0314 - acc: 0.9906 - val_loss: 0.0193 - val_acc: 0.9931\n",
      "Epoch 122/200\n",
      "60000/60000 [==============================] - 54s 904us/step - loss: 0.0322 - acc: 0.9908 - val_loss: 0.0210 - val_acc: 0.9927\n",
      "Epoch 123/200\n",
      "60000/60000 [==============================] - 54s 906us/step - loss: 0.0307 - acc: 0.9912 - val_loss: 0.0228 - val_acc: 0.9934\n",
      "Epoch 124/200\n",
      "60000/60000 [==============================] - 55s 909us/step - loss: 0.0312 - acc: 0.9908 - val_loss: 0.0214 - val_acc: 0.9935\n",
      "Epoch 125/200\n",
      "60000/60000 [==============================] - 54s 905us/step - loss: 0.0328 - acc: 0.9905 - val_loss: 0.0228 - val_acc: 0.9933\n",
      "Epoch 126/200\n",
      "60000/60000 [==============================] - 55s 910us/step - loss: 0.0305 - acc: 0.9907 - val_loss: 0.0213 - val_acc: 0.9933\n",
      "Epoch 127/200\n",
      "60000/60000 [==============================] - 54s 904us/step - loss: 0.0303 - acc: 0.9910 - val_loss: 0.0235 - val_acc: 0.9933\n",
      "Epoch 128/200\n",
      "60000/60000 [==============================] - 54s 904us/step - loss: 0.0314 - acc: 0.9906 - val_loss: 0.0198 - val_acc: 0.9933\n",
      "Epoch 129/200\n",
      "60000/60000 [==============================] - 54s 904us/step - loss: 0.0294 - acc: 0.9911 - val_loss: 0.0211 - val_acc: 0.9935\n",
      "Epoch 130/200\n",
      "60000/60000 [==============================] - 54s 908us/step - loss: 0.0301 - acc: 0.9910 - val_loss: 0.0220 - val_acc: 0.9928\n",
      "Epoch 131/200\n",
      "60000/60000 [==============================] - 54s 906us/step - loss: 0.0295 - acc: 0.9912 - val_loss: 0.0238 - val_acc: 0.9928\n",
      "Epoch 132/200\n",
      "60000/60000 [==============================] - 55s 909us/step - loss: 0.0320 - acc: 0.9904 - val_loss: 0.0214 - val_acc: 0.9929\n",
      "Epoch 133/200\n",
      "60000/60000 [==============================] - 55s 913us/step - loss: 0.0297 - acc: 0.9913 - val_loss: 0.0212 - val_acc: 0.9929\n",
      "Epoch 134/200\n",
      "60000/60000 [==============================] - 55s 913us/step - loss: 0.0284 - acc: 0.9920 - val_loss: 0.0214 - val_acc: 0.9928\n",
      "Epoch 135/200\n",
      "60000/60000 [==============================] - 54s 908us/step - loss: 0.0271 - acc: 0.9922 - val_loss: 0.0218 - val_acc: 0.9932\n",
      "Epoch 136/200\n",
      "60000/60000 [==============================] - 54s 903us/step - loss: 0.0295 - acc: 0.9912 - val_loss: 0.0186 - val_acc: 0.9937\n",
      "Epoch 137/200\n",
      "60000/60000 [==============================] - 54s 902us/step - loss: 0.0286 - acc: 0.9913 - val_loss: 0.0280 - val_acc: 0.9922\n",
      "Epoch 138/200\n",
      "60000/60000 [==============================] - 54s 898us/step - loss: 0.0299 - acc: 0.9912 - val_loss: 0.0228 - val_acc: 0.9931\n",
      "Epoch 139/200\n",
      "60000/60000 [==============================] - 54s 904us/step - loss: 0.0293 - acc: 0.9914 - val_loss: 0.0213 - val_acc: 0.9932\n",
      "Epoch 140/200\n",
      "60000/60000 [==============================] - 54s 905us/step - loss: 0.0284 - acc: 0.9916 - val_loss: 0.0256 - val_acc: 0.9932\n",
      "Epoch 141/200\n",
      "60000/60000 [==============================] - 54s 904us/step - loss: 0.0290 - acc: 0.9914 - val_loss: 0.0209 - val_acc: 0.9933\n",
      "Epoch 142/200\n",
      "60000/60000 [==============================] - 54s 905us/step - loss: 0.0275 - acc: 0.9919 - val_loss: 0.0207 - val_acc: 0.9927\n",
      "Epoch 143/200\n",
      "60000/60000 [==============================] - 55s 910us/step - loss: 0.0289 - acc: 0.9914 - val_loss: 0.0224 - val_acc: 0.9921\n",
      "Epoch 144/200\n",
      "60000/60000 [==============================] - 55s 911us/step - loss: 0.0268 - acc: 0.9920 - val_loss: 0.0222 - val_acc: 0.9928\n",
      "Epoch 145/200\n",
      "60000/60000 [==============================] - 54s 905us/step - loss: 0.0280 - acc: 0.9916 - val_loss: 0.0220 - val_acc: 0.9929\n",
      "Epoch 146/200\n",
      "60000/60000 [==============================] - 54s 900us/step - loss: 0.0252 - acc: 0.9921 - val_loss: 0.0243 - val_acc: 0.9935\n",
      "Epoch 147/200\n",
      "60000/60000 [==============================] - 54s 907us/step - loss: 0.0273 - acc: 0.9920 - val_loss: 0.0213 - val_acc: 0.9939\n",
      "Epoch 148/200\n",
      "60000/60000 [==============================] - 54s 903us/step - loss: 0.0277 - acc: 0.9919 - val_loss: 0.0240 - val_acc: 0.9926\n",
      "Epoch 149/200\n",
      "60000/60000 [==============================] - 54s 902us/step - loss: 0.0278 - acc: 0.9914 - val_loss: 0.0220 - val_acc: 0.9929\n",
      "Epoch 150/200\n",
      "60000/60000 [==============================] - 54s 905us/step - loss: 0.0267 - acc: 0.9921 - val_loss: 0.0251 - val_acc: 0.9929\n",
      "Epoch 151/200\n",
      "60000/60000 [==============================] - 55s 909us/step - loss: 0.0265 - acc: 0.9922 - val_loss: 0.0234 - val_acc: 0.9926\n",
      "Epoch 152/200\n",
      "60000/60000 [==============================] - 54s 901us/step - loss: 0.0268 - acc: 0.9921 - val_loss: 0.0228 - val_acc: 0.9927\n",
      "Epoch 153/200\n",
      "60000/60000 [==============================] - 54s 899us/step - loss: 0.0278 - acc: 0.9922 - val_loss: 0.0216 - val_acc: 0.9935\n",
      "Epoch 154/200\n",
      "60000/60000 [==============================] - 54s 902us/step - loss: 0.0261 - acc: 0.9923 - val_loss: 0.0220 - val_acc: 0.9929\n",
      "Epoch 155/200\n",
      "60000/60000 [==============================] - 54s 906us/step - loss: 0.0261 - acc: 0.9921 - val_loss: 0.0218 - val_acc: 0.9936\n",
      "Epoch 156/200\n",
      "60000/60000 [==============================] - 54s 900us/step - loss: 0.0285 - acc: 0.9919 - val_loss: 0.0199 - val_acc: 0.9935\n",
      "Epoch 157/200\n",
      "60000/60000 [==============================] - 54s 898us/step - loss: 0.0271 - acc: 0.9923 - val_loss: 0.0225 - val_acc: 0.9930\n",
      "Epoch 158/200\n",
      "60000/60000 [==============================] - 54s 899us/step - loss: 0.0258 - acc: 0.9923 - val_loss: 0.0241 - val_acc: 0.9931\n",
      "Epoch 159/200\n",
      "60000/60000 [==============================] - 54s 896us/step - loss: 0.0270 - acc: 0.9927 - val_loss: 0.0224 - val_acc: 0.9929\n",
      "Epoch 160/200\n",
      "60000/60000 [==============================] - 54s 903us/step - loss: 0.0250 - acc: 0.9923 - val_loss: 0.0197 - val_acc: 0.9941\n",
      "Epoch 161/200\n",
      "60000/60000 [==============================] - 55s 910us/step - loss: 0.0261 - acc: 0.9922 - val_loss: 0.0215 - val_acc: 0.9932\n",
      "Epoch 162/200\n",
      "60000/60000 [==============================] - 54s 903us/step - loss: 0.0268 - acc: 0.9923 - val_loss: 0.0221 - val_acc: 0.9932\n",
      "Epoch 163/200\n",
      "60000/60000 [==============================] - 54s 904us/step - loss: 0.0236 - acc: 0.9928 - val_loss: 0.0214 - val_acc: 0.9940\n",
      "Epoch 164/200\n",
      "60000/60000 [==============================] - 55s 911us/step - loss: 0.0249 - acc: 0.9924 - val_loss: 0.0201 - val_acc: 0.9929\n",
      "Epoch 165/200\n",
      "60000/60000 [==============================] - 55s 910us/step - loss: 0.0246 - acc: 0.9930 - val_loss: 0.0211 - val_acc: 0.9936\n",
      "Epoch 166/200\n",
      "60000/60000 [==============================] - 54s 906us/step - loss: 0.0241 - acc: 0.9928 - val_loss: 0.0219 - val_acc: 0.9929\n",
      "Epoch 167/200\n",
      "60000/60000 [==============================] - 54s 907us/step - loss: 0.0249 - acc: 0.9927 - val_loss: 0.0187 - val_acc: 0.9930\n",
      "Epoch 168/200\n",
      "60000/60000 [==============================] - 54s 908us/step - loss: 0.0254 - acc: 0.9928 - val_loss: 0.0206 - val_acc: 0.9930\n",
      "Epoch 169/200\n",
      "60000/60000 [==============================] - 54s 906us/step - loss: 0.0250 - acc: 0.9924 - val_loss: 0.0204 - val_acc: 0.9929\n",
      "Epoch 170/200\n",
      "60000/60000 [==============================] - 54s 904us/step - loss: 0.0215 - acc: 0.9933 - val_loss: 0.0209 - val_acc: 0.9925\n",
      "Epoch 171/200\n",
      "60000/60000 [==============================] - 54s 906us/step - loss: 0.0249 - acc: 0.9925 - val_loss: 0.0203 - val_acc: 0.9941\n",
      "Epoch 172/200\n",
      "60000/60000 [==============================] - 54s 903us/step - loss: 0.0247 - acc: 0.9929 - val_loss: 0.0210 - val_acc: 0.9942\n",
      "Epoch 173/200\n",
      "60000/60000 [==============================] - 54s 908us/step - loss: 0.0233 - acc: 0.9931 - val_loss: 0.0223 - val_acc: 0.9934\n",
      "Epoch 174/200\n",
      "60000/60000 [==============================] - 54s 908us/step - loss: 0.0232 - acc: 0.9930 - val_loss: 0.0227 - val_acc: 0.9937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/200\n",
      "60000/60000 [==============================] - 54s 905us/step - loss: 0.0216 - acc: 0.9938 - val_loss: 0.0213 - val_acc: 0.9940\n",
      "Epoch 176/200\n",
      "60000/60000 [==============================] - 54s 907us/step - loss: 0.0250 - acc: 0.9928 - val_loss: 0.0192 - val_acc: 0.9933\n",
      "Epoch 177/200\n",
      "60000/60000 [==============================] - 54s 905us/step - loss: 0.0225 - acc: 0.9933 - val_loss: 0.0255 - val_acc: 0.9930\n",
      "Epoch 178/200\n",
      "60000/60000 [==============================] - 55s 909us/step - loss: 0.0232 - acc: 0.9935 - val_loss: 0.0202 - val_acc: 0.9941\n",
      "Epoch 179/200\n",
      "60000/60000 [==============================] - 55s 911us/step - loss: 0.0223 - acc: 0.9937 - val_loss: 0.0216 - val_acc: 0.9933\n",
      "Epoch 180/200\n",
      "60000/60000 [==============================] - 55s 909us/step - loss: 0.0244 - acc: 0.9929 - val_loss: 0.0264 - val_acc: 0.9930\n",
      "Epoch 181/200\n",
      "60000/60000 [==============================] - 55s 912us/step - loss: 0.0218 - acc: 0.9935 - val_loss: 0.0199 - val_acc: 0.9941\n",
      "Epoch 182/200\n",
      "60000/60000 [==============================] - 54s 907us/step - loss: 0.0246 - acc: 0.9926 - val_loss: 0.0201 - val_acc: 0.9932\n",
      "Epoch 183/200\n",
      "60000/60000 [==============================] - 54s 905us/step - loss: 0.0226 - acc: 0.9933 - val_loss: 0.0209 - val_acc: 0.9929\n",
      "Epoch 184/200\n",
      "60000/60000 [==============================] - 54s 904us/step - loss: 0.0219 - acc: 0.9937 - val_loss: 0.0211 - val_acc: 0.9935\n",
      "Epoch 185/200\n",
      "60000/60000 [==============================] - 54s 906us/step - loss: 0.0245 - acc: 0.9928 - val_loss: 0.0198 - val_acc: 0.9933\n",
      "Epoch 186/200\n",
      "60000/60000 [==============================] - 55s 909us/step - loss: 0.0216 - acc: 0.9929 - val_loss: 0.0219 - val_acc: 0.9927\n",
      "Epoch 187/200\n",
      "60000/60000 [==============================] - 55s 911us/step - loss: 0.0215 - acc: 0.9939 - val_loss: 0.0212 - val_acc: 0.9933\n",
      "Epoch 188/200\n",
      "60000/60000 [==============================] - 55s 909us/step - loss: 0.0228 - acc: 0.9931 - val_loss: 0.0225 - val_acc: 0.9933\n",
      "Epoch 189/200\n",
      "60000/60000 [==============================] - 54s 901us/step - loss: 0.0233 - acc: 0.9930 - val_loss: 0.0207 - val_acc: 0.9933\n",
      "Epoch 190/200\n",
      "60000/60000 [==============================] - 54s 897us/step - loss: 0.0207 - acc: 0.9937 - val_loss: 0.0227 - val_acc: 0.9929\n",
      "Epoch 191/200\n",
      "60000/60000 [==============================] - 55s 910us/step - loss: 0.0217 - acc: 0.9934 - val_loss: 0.0243 - val_acc: 0.9936\n",
      "Epoch 192/200\n",
      "60000/60000 [==============================] - 55s 915us/step - loss: 0.0214 - acc: 0.9938 - val_loss: 0.0223 - val_acc: 0.9936\n",
      "Epoch 193/200\n",
      "60000/60000 [==============================] - 54s 895us/step - loss: 0.0198 - acc: 0.9942 - val_loss: 0.0315 - val_acc: 0.9909\n",
      "Epoch 194/200\n",
      "60000/60000 [==============================] - 54s 899us/step - loss: 0.0222 - acc: 0.9935 - val_loss: 0.0212 - val_acc: 0.9932\n",
      "Epoch 195/200\n",
      "60000/60000 [==============================] - 54s 895us/step - loss: 0.0237 - acc: 0.9932 - val_loss: 0.0225 - val_acc: 0.9935\n",
      "Epoch 196/200\n",
      "60000/60000 [==============================] - 54s 897us/step - loss: 0.0218 - acc: 0.9938 - val_loss: 0.0256 - val_acc: 0.9922\n",
      "Epoch 197/200\n",
      "60000/60000 [==============================] - 54s 898us/step - loss: 0.0212 - acc: 0.9940 - val_loss: 0.0214 - val_acc: 0.9941\n",
      "Epoch 198/200\n",
      "60000/60000 [==============================] - 54s 897us/step - loss: 0.0226 - acc: 0.9932 - val_loss: 0.0219 - val_acc: 0.9931\n",
      "Epoch 199/200\n",
      "60000/60000 [==============================] - 54s 896us/step - loss: 0.0194 - acc: 0.9941 - val_loss: 0.0202 - val_acc: 0.9932\n",
      "Epoch 200/200\n",
      "60000/60000 [==============================] - 47s 791us/step - loss: 0.0205 - acc: 0.9940 - val_loss: 0.0231 - val_acc: 0.9924\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the Model\n",
    "#earlyStopping=keras.callbacks.EarlyStopping(monitor='val_acc', min_delta=0, patience=13, verbose=1, mode='auto')\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "#                    callbacks=[earlyStopping],\n",
    "                    validation_data=(x_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f99e6474d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train acc','val acc'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKcj/B0pfJIn++n8CAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f99e41f3438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train loss','Val Loss'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0231215041352\n",
      "Test accuracy: 0.9924\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': [0.77971809501647948, 0.26261716831922532, 0.20065750159025192, 0.11935803133221343, 0.11598861263245344, 0.081397301126550886, 0.078648706214898265, 0.074535714305122389, 0.065274106562556694, 0.062529684096225543, 0.055221236115298236, 0.055675893244717736, 0.050350134266278476, 0.046229783060192133, 0.045597595057450237, 0.048043135144526607, 0.042480586235149533, 0.040255940635947625, 0.041718124583415922, 0.054224557799031028, 0.038818389668005694, 0.052043629532447087, 0.041000950569000272, 0.0339823463331064, 0.033761745697943844, 0.035117802418576323, 0.24279511128664016, 0.032010784191952552, 0.036682530573650729, 0.033553621753971676, 0.031484930958904443, 0.032949420557596025, 0.03434162649688078, 0.031608157441485672, 0.029474579346850806, 0.029195806549319241, 0.031593737830025927, 0.027709643489738301, 0.027124296583638352, 0.030962103742093315, 0.030583792797857313, 0.025875279705240974, 0.026750675070725264, 0.02761129701930622, 0.025748735310150369, 0.027249629734337213, 0.027643149547851499, 0.028532651346627972, 0.027908685850271651, 0.026552743762338651, 0.028682001582156228, 0.025799326350753837, 0.024727782785323508, 0.030242387427845095, 0.024907003002693818, 0.027323484786938933, 0.025798772402704343, 0.027837994194103523, 0.026976439630432288, 0.027909325799860382, 0.026248016958079098, 0.022562359229576397, 0.025509495305654856, 0.024136039162930684, 0.02760746804333903, 0.028363204186346958, 0.023032246342239524, 0.02790264278671202, 0.029811206398198557, 0.024418731235649464, 0.022452195711982495, 0.024536015389751992, 0.023023424818663624, 0.022081284415121628, 0.024028198234437876, 0.02510715929474536, 0.021901790164582782, 0.02159683475785714, 0.02228141433123965, 0.02409756194766087, 0.021285877112257004, 0.023029589320486411, 0.023211499744523464, 0.0218597993304189, 0.022403125605866079, 0.023775950038127484, 0.022039281315174596, 0.028624966095245327, 0.022985417698062883, 0.02135478780656631, 0.021976020303491533, 0.021863695520909641, 0.02183177580731608, 0.022212312948434555, 0.023722424114594198, 0.022074538461068004, 0.022653728395899814, 0.023773817094665174, 0.026170240321580059, 0.022771443661109517, 0.022916735983381294, 0.023129533791850555, 0.022773833327879401, 0.022068781941238194, 0.020542166339820686, 0.019995115686185453, 0.021508778116040777, 0.021491961755941882, 0.021553184000329201, 0.021871539199452492, 0.024290505444028714, 0.026961115289812369, 0.021509609708875176, 0.021672294627697375, 0.025771804708783749, 0.022213051559908128, 0.021815403738777606, 0.021017794207040787, 0.021693620237854521, 0.021358332878547298, 0.01926860784987057, 0.020961026843075523, 0.022843236264615006, 0.021353236233087592, 0.022771199595626058, 0.021314528906425403, 0.023504608986645144, 0.019823908788959305, 0.021142138903239537, 0.022027372261063376, 0.023774205906248971, 0.021357255890608211, 0.021171372490579505, 0.021415382774676254, 0.021787596191507237, 0.018602452751796592, 0.028004362531641892, 0.022768725225988055, 0.02125090343832926, 0.025575106217781557, 0.020898388593393248, 0.020650741894287786, 0.022426704369911749, 0.022154706348576473, 0.022037967085570927, 0.024334432540820673, 0.021299786218029113, 0.023996575983187905, 0.021971227787710722, 0.025080413581671745, 0.023353894463578762, 0.022824665100451058, 0.021604813734610796, 0.022037349210050888, 0.021832202740606408, 0.019904018986222946, 0.022471894778831665, 0.024100248035528786, 0.022354075749751429, 0.019747654653972494, 0.021539328540044426, 0.022097181635948801, 0.021419283699248264, 0.02011100323807459, 0.021131684676848637, 0.021932466090423985, 0.018678003838982476, 0.020647482831707111, 0.020381627947497691, 0.02087394455806825, 0.020287260397340107, 0.020978603376139018, 0.022270326887417924, 0.022683571091264093, 0.021347902999453709, 0.019194670305619728, 0.025505629545911325, 0.020192908471963346, 0.021638806318299428, 0.026383276976108483, 0.019948337407575855, 0.020057790783598466, 0.020856327609781691, 0.021072919743034435, 0.01976962673013595, 0.021938364982079291, 0.02118377848264099, 0.022517568960431892, 0.020659861245355567, 0.022678780017357712, 0.024312548257401524, 0.022284175174450003, 0.031530962230241856, 0.021178471047089441, 0.02249232587078186, 0.025647048846193593, 0.021410744981075914, 0.021926650987600077, 0.020209215583721653, 0.023121503821993065], 'val_acc': [0.72799999999999998, 0.92400000000000004, 0.93979999999999997, 0.9617, 0.96679999999999999, 0.97460000000000002, 0.97450000000000003, 0.97619999999999996, 0.97870000000000001, 0.97999999999999998, 0.98229999999999995, 0.98240000000000005, 0.98340000000000005, 0.98509999999999998, 0.98470000000000002, 0.98540000000000005, 0.98680000000000001, 0.98760000000000003, 0.98670000000000002, 0.98229999999999995, 0.98750000000000004, 0.98460000000000003, 0.98709999999999998, 0.98950000000000005, 0.98909999999999998, 0.98950000000000005, 0.93759999999999999, 0.99009999999999998, 0.98780000000000001, 0.98960000000000004, 0.99019999999999997, 0.98919999999999997, 0.98950000000000005, 0.98960000000000004, 0.99039999999999995, 0.99039999999999995, 0.99099999999999999, 0.99050000000000005, 0.99050000000000005, 0.99009999999999998, 0.98970000000000002, 0.99129999999999996, 0.99109999999999998, 0.99109999999999998, 0.99139999999999995, 0.99050000000000005, 0.9899, 0.9899, 0.99099999999999999, 0.99129999999999996, 0.99099999999999999, 0.9919, 0.99180000000000001, 0.9909, 0.99119999999999997, 0.99060000000000004, 0.99180000000000001, 0.99029999999999996, 0.99129999999999996, 0.99139999999999995, 0.99150000000000005, 0.99219999999999997, 0.99219999999999997, 0.99209999999999998, 0.99060000000000004, 0.99139999999999995, 0.99239999999999995, 0.9909, 0.99150000000000005, 0.99250000000000005, 0.99199999999999999, 0.99239999999999995, 0.99209999999999998, 0.99270000000000003, 0.99209999999999998, 0.99170000000000003, 0.99180000000000001, 0.99270000000000003, 0.99260000000000004, 0.99199999999999999, 0.99280000000000002, 0.99180000000000001, 0.9929, 0.99339999999999995, 0.99209999999999998, 0.99270000000000003, 0.99280000000000002, 0.99060000000000004, 0.99299999999999999, 0.99309999999999998, 0.99260000000000004, 0.99270000000000003, 0.99229999999999996, 0.99260000000000004, 0.99319999999999997, 0.99299999999999999, 0.99280000000000002, 0.99299999999999999, 0.99250000000000005, 0.9919, 0.99270000000000003, 0.99209999999999998, 0.9929, 0.99299999999999999, 0.99250000000000005, 0.99319999999999997, 0.99239999999999995, 0.99239999999999995, 0.99299999999999999, 0.99380000000000002, 0.9919, 0.99250000000000005, 0.99309999999999998, 0.99280000000000002, 0.99270000000000003, 0.99199999999999999, 0.99309999999999998, 0.99360000000000004, 0.99280000000000002, 0.99250000000000005, 0.99309999999999998, 0.99270000000000003, 0.99339999999999995, 0.99350000000000005, 0.99329999999999996, 0.99329999999999996, 0.99329999999999996, 0.99329999999999996, 0.99350000000000005, 0.99280000000000002, 0.99280000000000002, 0.9929, 0.9929, 0.99280000000000002, 0.99319999999999997, 0.99370000000000003, 0.99219999999999997, 0.99309999999999998, 0.99319999999999997, 0.99319999999999997, 0.99329999999999996, 0.99270000000000003, 0.99209999999999998, 0.99280000000000002, 0.9929, 0.99350000000000005, 0.99390000000000001, 0.99260000000000004, 0.9929, 0.9929, 0.99260000000000004, 0.99270000000000003, 0.99350000000000005, 0.9929, 0.99360000000000004, 0.99350000000000005, 0.99299999999999999, 0.99309999999999998, 0.9929, 0.99409999999999998, 0.99319999999999997, 0.99319999999999997, 0.99399999999999999, 0.9929, 0.99360000000000004, 0.9929, 0.99299999999999999, 0.99299999999999999, 0.9929, 0.99250000000000005, 0.99409999999999998, 0.99419999999999997, 0.99339999999999995, 0.99370000000000003, 0.99399999999999999, 0.99329999999999996, 0.99299999999999999, 0.99409999999999998, 0.99329999999999996, 0.99299999999999999, 0.99409999999999998, 0.99319999999999997, 0.9929, 0.99350000000000005, 0.99329999999999996, 0.99270000000000003, 0.99329999999999996, 0.99329999999999996, 0.99329999999999996, 0.9929, 0.99360000000000004, 0.99360000000000004, 0.9909, 0.99319999999999997, 0.99350000000000005, 0.99219999999999997, 0.99409999999999998, 0.99309999999999998, 0.99319999999999997, 0.99239999999999995], 'loss': [2.0327022776285806, 0.8203836440086365, 0.45434570430119831, 0.33732793943881989, 0.27380846944252651, 0.24055378800233204, 0.21860154808759688, 0.19480682741006217, 0.17699231988390288, 0.16692868228654067, 0.15545785356859365, 0.14837053941289585, 0.14113879676659902, 0.1377073674370845, 0.12912741185774407, 0.12437332974572976, 0.12044943485955398, 0.11685929669439793, 0.10820735919723908, 0.10808030539999405, 0.10494204792131981, 0.098947900032500424, 0.097943053813278669, 0.096534886887669563, 0.092370522180447973, 0.092114950251827643, 0.090260887932280695, 0.087248565746843809, 0.088148190522938971, 0.084196278477708497, 0.08245230268761515, 0.080456425327310954, 0.078644624814018613, 0.076977231137206156, 0.079934586186707013, 0.077614011489848297, 0.073261615403741598, 0.070641708616415666, 0.071361591257403295, 0.070487022254119319, 0.070195280975103372, 0.067910795086746412, 0.068148459320391222, 0.066139039448897041, 0.066419432811190685, 0.065651601013789571, 0.060220258499681947, 0.062025124890170993, 0.061175412076587478, 0.061611529568893215, 0.05907547192970912, 0.059877513131995998, 0.055355112624168396, 0.058935910024493936, 0.056113536177575585, 0.056306866389637195, 0.053959103215423722, 0.054221416817915938, 0.055428485012551147, 0.056188446432476245, 0.053138987795884413, 0.053856456389712794, 0.054078358185725907, 0.051154543742723761, 0.050697960097777349, 0.050105545294408999, 0.05095122266088923, 0.049782052404060959, 0.049696253720484675, 0.050794374744594098, 0.049658160768387222, 0.047463179225288331, 0.044637182137804723, 0.047026550610736011, 0.046964350671212497, 0.046380482427651686, 0.048295841361023488, 0.043317599511146547, 0.044296896650145454, 0.043543338395965595, 0.042113951825598878, 0.041638579985871914, 0.041125201188928137, 0.043892541952244936, 0.04273186570216591, 0.041264778792206198, 0.04213073969359199, 0.040383095533028247, 0.039273691109164309, 0.04214226204628746, 0.041944423409458247, 0.038327140013640744, 0.04139271758534014, 0.039940082116033108, 0.037643620633861674, 0.039089165533830725, 0.038482446187098202, 0.035745651194468764, 0.035660594443852701, 0.038450075044824429, 0.035706638056971135, 0.03782330294940621, 0.038756678949048121, 0.035250968083133924, 0.036876823521576202, 0.035392757752972341, 0.034126617129193619, 0.035780738399426144, 0.033876763520917542, 0.035600653009116648, 0.033668161251364896, 0.03563956417720765, 0.033028796585408658, 0.033793117716442791, 0.033289967178227381, 0.033508187171397731, 0.033774376898088182, 0.031897561168003206, 0.032875783342495558, 0.030755924702435732, 0.031401323396495234, 0.032219161378918212, 0.030742236350864791, 0.031227428420896951, 0.032808749404704816, 0.030548542453643555, 0.030274154102103785, 0.03136031210342189, 0.029351813216010731, 0.030077803088631481, 0.029535779391035126, 0.032031362649115422, 0.029707365743350238, 0.028437985888984985, 0.027143552935744324, 0.029458778892674793, 0.028647929100684512, 0.029857326239262086, 0.029301103763445281, 0.028437105311220512, 0.028956767790655917, 0.0275113906956433, 0.028860287267660413, 0.026772442431142553, 0.027998450351386175, 0.025200326755464388, 0.027329927268174167, 0.027698673236990969, 0.027807620677631349, 0.026714141346296915, 0.026517552300853033, 0.026750246964682204, 0.027792167542114232, 0.026089163292245938, 0.026140919036720878, 0.028463469902480332, 0.027131286174757407, 0.025753195675159806, 0.027036995847693954, 0.025048195573866058, 0.026085983963318481, 0.026822740313534935, 0.023639537777487809, 0.024922071298211813, 0.024599916058056989, 0.024101615138701162, 0.024852893450297415, 0.025366624790333057, 0.024988815120320456, 0.021529468240806211, 0.024932535369663188, 0.024717136045514294, 0.023274561011030648, 0.023204736967120939, 0.021615731340596297, 0.02496797454832898, 0.022512619225595457, 0.023166390143946045, 0.022331534159202904, 0.024381908040163883, 0.021809521718299949, 0.024579291953784801, 0.022640742501632002, 0.021906829532164072, 0.024517627238295973, 0.021627144594998874, 0.02150527593931183, 0.022787330884338979, 0.023251814396198219, 0.020663917573099023, 0.021727923378327008, 0.021424494262646962, 0.019762099205139869, 0.02215828723835099, 0.023677502756100147, 0.021823203730587073, 0.02115429209790309, 0.022591440863717192, 0.019428377494569091, 0.020483707075606799], 'acc': [0.24515000000000001, 0.72514999999999996, 0.86219999999999997, 0.9022, 0.92125000000000001, 0.93154999999999999, 0.93903333333333339, 0.94458333333333333, 0.94989999999999997, 0.95301666666666662, 0.95658333333333334, 0.95765, 0.96056666666666668, 0.96240000000000003, 0.96458333333333335, 0.96550000000000002, 0.96655000000000002, 0.96788333333333332, 0.97019999999999995, 0.97053333333333336, 0.97111666666666663, 0.97258333333333336, 0.9725166666666667, 0.97330000000000005, 0.97421666666666662, 0.97424999999999995, 0.97484999999999999, 0.97528333333333328, 0.97581666666666667, 0.97573333333333334, 0.97703333333333331, 0.97753333333333337, 0.97818333333333329, 0.97883333333333333, 0.97831666666666661, 0.97838333333333338, 0.97893333333333332, 0.97978333333333334, 0.9801333333333333, 0.98021666666666663, 0.98068333333333335, 0.98086666666666666, 0.98098333333333332, 0.98119999999999996, 0.98103333333333331, 0.98131666666666661, 0.98281666666666667, 0.98226666666666662, 0.98250000000000004, 0.98278333333333334, 0.98366666666666669, 0.9831833333333333, 0.98399999999999999, 0.98331666666666662, 0.98378333333333334, 0.98406666666666665, 0.98499999999999999, 0.98483333333333334, 0.98411666666666664, 0.98429999999999995, 0.98488333333333333, 0.98441666666666672, 0.98460000000000003, 0.98531666666666662, 0.98531666666666662, 0.98638333333333328, 0.98533333333333328, 0.98658333333333337, 0.98634999999999995, 0.98583333333333334, 0.98631666666666662, 0.98675000000000002, 0.9869, 0.98699999999999999, 0.98666666666666669, 0.98676666666666668, 0.98673333333333335, 0.98786666666666667, 0.98740000000000006, 0.98794999999999999, 0.98821666666666663, 0.98796666666666666, 0.98798333333333332, 0.98713333333333331, 0.98831666666666662, 0.98883333333333334, 0.98788333333333334, 0.98875000000000002, 0.98860000000000003, 0.98796666666666666, 0.98801666666666665, 0.98858333333333337, 0.98798333333333332, 0.98863333333333336, 0.98924999999999996, 0.98821666666666663, 0.98875000000000002, 0.98878333333333335, 0.98946666666666672, 0.98916666666666664, 0.98980000000000001, 0.98870000000000002, 0.98885000000000001, 0.98936666666666662, 0.98899999999999999, 0.9899, 0.98965000000000003, 0.99008333333333332, 0.99031666666666662, 0.98973333333333335, 0.99016666666666664, 0.98965000000000003, 0.99065000000000003, 0.99021666666666663, 0.99058333333333337, 0.99041666666666661, 0.99016666666666664, 0.99068333333333336, 0.99073333333333335, 0.99131666666666662, 0.99058333333333337, 0.99078333333333335, 0.99118333333333331, 0.99083333333333334, 0.99048333333333338, 0.9906666666666667, 0.99101666666666666, 0.9906166666666667, 0.99111666666666665, 0.99101666666666666, 0.9912333333333333, 0.99043333333333339, 0.99128333333333329, 0.99196666666666666, 0.99216666666666664, 0.99114999999999998, 0.99134999999999995, 0.99119999999999997, 0.99136666666666662, 0.99160000000000004, 0.99138333333333328, 0.99185000000000001, 0.99143333333333339, 0.99201666666666666, 0.99160000000000004, 0.99206666666666665, 0.99198333333333333, 0.9919, 0.99143333333333339, 0.99206666666666665, 0.99221666666666664, 0.99214999999999998, 0.99219999999999997, 0.99229999999999996, 0.99214999999999998, 0.9919, 0.9922833333333333, 0.99229999999999996, 0.99268333333333336, 0.99234999999999995, 0.99216666666666664, 0.9922833333333333, 0.99280000000000002, 0.99241666666666661, 0.99299999999999999, 0.99280000000000002, 0.99270000000000003, 0.99276666666666669, 0.99236666666666662, 0.99331666666666663, 0.99253333333333338, 0.99291666666666667, 0.99308333333333332, 0.99303333333333332, 0.99381666666666668, 0.99281666666666668, 0.9932833333333333, 0.99355000000000004, 0.99368333333333336, 0.99295, 0.99351666666666671, 0.99258333333333337, 0.99331666666666663, 0.9936666666666667, 0.99280000000000002, 0.99288333333333334, 0.99390000000000001, 0.99308333333333332, 0.99301666666666666, 0.99368333333333336, 0.99343333333333328, 0.99380000000000002, 0.99421666666666664, 0.99348333333333338, 0.99316666666666664, 0.99378333333333335, 0.99398333333333333, 0.99318333333333331, 0.99411666666666665, 0.99395]}\n"
     ]
    }
   ],
   "source": [
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "data = pd.DataFrame(history.history)\n",
    "nome = 'DoubleConvMNISTNormDrop_t2' + str(datetime.datetime.now())+'.json'\n",
    "data = data.to_json()\n",
    "with open(nome, \"w+\") as output_file:\n",
    "    output_file.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
