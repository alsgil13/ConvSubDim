{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Softmax\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Reshape, GlobalAveragePooling2D, GlobalAveragePooling1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.initializers import RandomNormal\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "num_classes = 10 #pegar automaticamente NumPy.Unique\n",
    "epochs = 200\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Cifar-10 Data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "#Adicionando Canal do DataSet (Channel do MNIST eh 1)\n",
    "x_train = np.reshape(x_train, (len(x_train),28,28, 1))\n",
    "x_test = np.reshape(x_test, (len(x_test),28,28, 1))\n",
    "\n",
    "\n",
    "#x_train.shape\n",
    "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
    "#channel=1\n",
    "\n",
    "x_train.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#\n",
    "x_train.shape\n",
    "\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert to one hot encoing \n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#Filters = IMG_width/2 * 7\n",
    "model.add(Conv2D(98, #alterado de 168 para 98\n",
    "                 (5,5), #alterado de 3 para 5 \n",
    "                 strides=(2,2), \n",
    "                 activation='relu', \n",
    "                 padding='same',\n",
    "                 data_format='channels_last',\n",
    "                 use_bias=True, \n",
    "                 kernel_initializer=RandomNormal(mean=0.0, stddev=0.05, seed=None), \n",
    "                 bias_initializer='zeros',\n",
    "                 input_shape=(img_height, img_width, channel)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), \n",
    "                       strides=(2,2)))\n",
    "\n",
    "#Normalization:\n",
    "#calculo da quantidade de filtros da normalização:\n",
    "# Width*heigth da saída após a primeira camada de convolução+pooling\n",
    "model.add(Conv2D(49, \n",
    "                 (1,1), \n",
    "                 strides=(1,1), \n",
    "                 activation='relu', \n",
    "                 padding='same',\n",
    "                 kernel_initializer=RandomNormal(mean=0.0, stddev=0.05, seed=None), \n",
    "                 data_format='channels_last'))\n",
    "model.add(Conv2D(49, \n",
    "                 (1,1), \n",
    "                 strides=(1,1), \n",
    "                 activation='relu', \n",
    "                 padding='same',\n",
    "                 kernel_initializer=RandomNormal(mean=0.0, stddev=0.05, seed=None),                  \n",
    "                 data_format='channels_last'))\n",
    "\n",
    "#Filters = IMG_width/2 * 9\n",
    "model.add(Conv2D(126, \n",
    "                 (5,5), \n",
    "                 strides=(2,2), \n",
    "                 activation='relu', \n",
    "                 padding='same',\n",
    "                 data_format='channels_last',\n",
    "                 use_bias=True, \n",
    "                 kernel_initializer=RandomNormal(mean=0.0, stddev=0.05, seed=None), \n",
    "                 bias_initializer='zeros',\n",
    "                 input_shape=(img_height, img_width, channel)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), \n",
    "                       strides=(2,2)))\n",
    "#Normalization:\n",
    "#calculo da quantidade de filtros da normalização:\n",
    "# Width*heigth da saída após a primeira camada de convolução+pooling\n",
    "model.add(Conv2D(49, \n",
    "                 (1,1), \n",
    "                 strides=(1,1), \n",
    "                 activation='relu', \n",
    "                 padding='same',\n",
    "                 kernel_initializer=RandomNormal(mean=0.0, stddev=0.05, seed=None),                  \n",
    "                 data_format='channels_last'))\n",
    "model.add(Conv2D(49, \n",
    "                 (1,1), \n",
    "                 strides=(1,1), \n",
    "                 activation='relu', \n",
    "                 padding='same',\n",
    "                 kernel_initializer=RandomNormal(mean=0.0, stddev=0.05, seed=None),                  \n",
    "                 data_format='channels_last'))\n",
    "\n",
    "model.add(Flatten())\n",
    "#IMG_width^ 2\n",
    "model.add(Dense(784, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#camada anterior/2\n",
    "model.add(Dense(392, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#Num de classes\n",
    "model.add(Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 98)        2548      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 98)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 49)          4851      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 49)          2450      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 126)         154476    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 126)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 2, 2, 49)          6223      \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 2, 2, 49)          2450      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 784)               154448    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 392)               307720    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 392)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                3930      \n",
      "=================================================================\n",
      "Total params: 639,096\n",
      "Trainable params: 639,096\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print the model summary\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# determine Loss function and Optimizer\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=0.01, momentum=0.02, decay=0.0, nesterov=False),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "60000/60000 [==============================] - 32s 528us/step - loss: 0.6898 - acc: 0.7690 - val_loss: 0.1570 - val_acc: 0.9525\n",
      "Epoch 2/200\n",
      "60000/60000 [==============================] - 32s 530us/step - loss: 0.1380 - acc: 0.9596 - val_loss: 0.0808 - val_acc: 0.9741\n",
      "Epoch 3/200\n",
      "60000/60000 [==============================] - 32s 532us/step - loss: 0.1008 - acc: 0.9706 - val_loss: 0.0499 - val_acc: 0.9835\n",
      "Epoch 4/200\n",
      "60000/60000 [==============================] - 32s 531us/step - loss: 0.0779 - acc: 0.9774 - val_loss: 0.0594 - val_acc: 0.9814\n",
      "Epoch 5/200\n",
      "60000/60000 [==============================] - 32s 530us/step - loss: 0.0665 - acc: 0.9804 - val_loss: 0.0460 - val_acc: 0.9843\n",
      "Epoch 6/200\n",
      "60000/60000 [==============================] - 32s 533us/step - loss: 0.0571 - acc: 0.9836 - val_loss: 0.0393 - val_acc: 0.9874\n",
      "Epoch 7/200\n",
      "60000/60000 [==============================] - 32s 533us/step - loss: 0.0501 - acc: 0.9849 - val_loss: 0.0400 - val_acc: 0.9868\n",
      "Epoch 8/200\n",
      "60000/60000 [==============================] - 32s 540us/step - loss: 0.0450 - acc: 0.9867 - val_loss: 0.0339 - val_acc: 0.9895\n",
      "Epoch 9/200\n",
      "60000/60000 [==============================] - 32s 535us/step - loss: 0.0393 - acc: 0.9885 - val_loss: 0.0410 - val_acc: 0.9870\n",
      "Epoch 10/200\n",
      "60000/60000 [==============================] - 32s 534us/step - loss: 0.0350 - acc: 0.9894 - val_loss: 0.0307 - val_acc: 0.9906\n",
      "Epoch 11/200\n",
      "60000/60000 [==============================] - 32s 539us/step - loss: 0.0316 - acc: 0.9906 - val_loss: 0.0415 - val_acc: 0.9877\n",
      "Epoch 12/200\n",
      "60000/60000 [==============================] - 32s 538us/step - loss: 0.0311 - acc: 0.9906 - val_loss: 0.0322 - val_acc: 0.9898\n",
      "Epoch 13/200\n",
      "60000/60000 [==============================] - 32s 539us/step - loss: 0.0282 - acc: 0.9913 - val_loss: 0.0335 - val_acc: 0.9896\n",
      "Epoch 14/200\n",
      "60000/60000 [==============================] - 32s 535us/step - loss: 0.0262 - acc: 0.9920 - val_loss: 0.0320 - val_acc: 0.9896\n",
      "Epoch 15/200\n",
      "60000/60000 [==============================] - 32s 536us/step - loss: 0.0240 - acc: 0.9927 - val_loss: 0.0314 - val_acc: 0.9901\n",
      "Epoch 16/200\n",
      "60000/60000 [==============================] - 32s 534us/step - loss: 0.0232 - acc: 0.9927 - val_loss: 0.0301 - val_acc: 0.9910\n",
      "Epoch 17/200\n",
      "60000/60000 [==============================] - 32s 537us/step - loss: 0.0200 - acc: 0.9940 - val_loss: 0.0385 - val_acc: 0.9888\n",
      "Epoch 18/200\n",
      "60000/60000 [==============================] - 32s 535us/step - loss: 0.0196 - acc: 0.9942 - val_loss: 0.0362 - val_acc: 0.9898\n",
      "Epoch 19/200\n",
      "60000/60000 [==============================] - 32s 538us/step - loss: 0.0173 - acc: 0.9945 - val_loss: 0.0392 - val_acc: 0.9892\n",
      "Epoch 20/200\n",
      "60000/60000 [==============================] - 32s 537us/step - loss: 0.0167 - acc: 0.9950 - val_loss: 0.0360 - val_acc: 0.9903\n",
      "Epoch 21/200\n",
      "60000/60000 [==============================] - 32s 536us/step - loss: 0.0152 - acc: 0.9951 - val_loss: 0.0353 - val_acc: 0.9901\n",
      "Epoch 22/200\n",
      "60000/60000 [==============================] - 32s 534us/step - loss: 0.0139 - acc: 0.9958 - val_loss: 0.0332 - val_acc: 0.9917\n",
      "Epoch 23/200\n",
      "60000/60000 [==============================] - 32s 536us/step - loss: 0.0147 - acc: 0.9951 - val_loss: 0.0318 - val_acc: 0.9918\n",
      "Epoch 24/200\n",
      "60000/60000 [==============================] - 32s 536us/step - loss: 0.0131 - acc: 0.9960 - val_loss: 0.0350 - val_acc: 0.9901\n",
      "Epoch 25/200\n",
      "60000/60000 [==============================] - 32s 534us/step - loss: 0.0119 - acc: 0.9964 - val_loss: 0.0436 - val_acc: 0.9888\n",
      "Epoch 26/200\n",
      "60000/60000 [==============================] - 32s 537us/step - loss: 0.0115 - acc: 0.9965 - val_loss: 0.0354 - val_acc: 0.9911\n",
      "Epoch 27/200\n",
      "60000/60000 [==============================] - 32s 535us/step - loss: 0.0112 - acc: 0.9968 - val_loss: 0.0382 - val_acc: 0.9899\n",
      "Epoch 28/200\n",
      "60000/60000 [==============================] - 32s 535us/step - loss: 0.0102 - acc: 0.9967 - val_loss: 0.0409 - val_acc: 0.9903\n",
      "Epoch 29/200\n",
      "60000/60000 [==============================] - 32s 536us/step - loss: 0.0101 - acc: 0.9970 - val_loss: 0.0414 - val_acc: 0.9904\n",
      "Epoch 30/200\n",
      "60000/60000 [==============================] - 32s 536us/step - loss: 0.0086 - acc: 0.9973 - val_loss: 0.0368 - val_acc: 0.9915\n",
      "Epoch 31/200\n",
      "60000/60000 [==============================] - 32s 534us/step - loss: 0.0089 - acc: 0.9971 - val_loss: 0.0357 - val_acc: 0.9917\n",
      "Epoch 32/200\n",
      "60000/60000 [==============================] - 32s 537us/step - loss: 0.0084 - acc: 0.9972 - val_loss: 0.0358 - val_acc: 0.9916\n",
      "Epoch 33/200\n",
      "60000/60000 [==============================] - 32s 536us/step - loss: 0.0089 - acc: 0.9969 - val_loss: 0.0785 - val_acc: 0.9827\n",
      "Epoch 34/200\n",
      "60000/60000 [==============================] - 32s 539us/step - loss: 0.0073 - acc: 0.9977 - val_loss: 0.0370 - val_acc: 0.9922\n",
      "Epoch 35/200\n",
      "60000/60000 [==============================] - 32s 538us/step - loss: 0.0085 - acc: 0.9973 - val_loss: 0.0357 - val_acc: 0.9909\n",
      "Epoch 36/200\n",
      "60000/60000 [==============================] - 32s 536us/step - loss: 0.0065 - acc: 0.9980 - val_loss: 0.0392 - val_acc: 0.9903\n",
      "Epoch 37/200\n",
      "60000/60000 [==============================] - 32s 536us/step - loss: 0.0061 - acc: 0.9983 - val_loss: 0.0399 - val_acc: 0.9914\n",
      "Epoch 38/200\n",
      "60000/60000 [==============================] - 32s 538us/step - loss: 0.0057 - acc: 0.9981 - val_loss: 0.0586 - val_acc: 0.9874\n",
      "Epoch 39/200\n",
      "60000/60000 [==============================] - 32s 538us/step - loss: 0.0057 - acc: 0.9983 - val_loss: 0.0434 - val_acc: 0.9916\n",
      "Epoch 40/200\n",
      "60000/60000 [==============================] - 32s 539us/step - loss: 0.0078 - acc: 0.9975 - val_loss: 0.0446 - val_acc: 0.9904\n",
      "Epoch 41/200\n",
      "60000/60000 [==============================] - 32s 537us/step - loss: 0.0070 - acc: 0.9978 - val_loss: 0.0453 - val_acc: 0.9907\n",
      "Epoch 42/200\n",
      "60000/60000 [==============================] - 32s 536us/step - loss: 0.0067 - acc: 0.9979 - val_loss: 0.0447 - val_acc: 0.9904\n",
      "Epoch 43/200\n",
      "60000/60000 [==============================] - 32s 538us/step - loss: 0.0069 - acc: 0.9976 - val_loss: 0.0461 - val_acc: 0.9903\n",
      "Epoch 44/200\n",
      "60000/60000 [==============================] - 32s 537us/step - loss: 0.0069 - acc: 0.9978 - val_loss: 0.0402 - val_acc: 0.9913\n",
      "Epoch 45/200\n",
      "60000/60000 [==============================] - 32s 540us/step - loss: 0.0044 - acc: 0.9986 - val_loss: 0.0399 - val_acc: 0.9918\n",
      "Epoch 46/200\n",
      "60000/60000 [==============================] - 32s 539us/step - loss: 0.0031 - acc: 0.9991 - val_loss: 0.0538 - val_acc: 0.9884\n",
      "Epoch 47/200\n",
      "60000/60000 [==============================] - 32s 537us/step - loss: 0.0047 - acc: 0.9986 - val_loss: 0.0413 - val_acc: 0.9912\n",
      "Epoch 48/200\n",
      "60000/60000 [==============================] - 32s 537us/step - loss: 0.0066 - acc: 0.9979 - val_loss: 0.0550 - val_acc: 0.9898\n",
      "Epoch 49/200\n",
      "60000/60000 [==============================] - 32s 535us/step - loss: 0.0058 - acc: 0.9980 - val_loss: 0.0379 - val_acc: 0.9923\n",
      "Epoch 50/200\n",
      "60000/60000 [==============================] - 32s 532us/step - loss: 0.0040 - acc: 0.9989 - val_loss: 0.0406 - val_acc: 0.9921\n",
      "Epoch 51/200\n",
      "60000/60000 [==============================] - 32s 533us/step - loss: 0.0045 - acc: 0.9986 - val_loss: 0.0461 - val_acc: 0.9910\n",
      "Epoch 52/200\n",
      "60000/60000 [==============================] - 32s 534us/step - loss: 0.0027 - acc: 0.9992 - val_loss: 0.0401 - val_acc: 0.9918\n",
      "Epoch 53/200\n",
      "60000/60000 [==============================] - 32s 533us/step - loss: 0.0023 - acc: 0.9993 - val_loss: 0.0436 - val_acc: 0.9915\n",
      "Epoch 54/200\n",
      "60000/60000 [==============================] - 32s 537us/step - loss: 0.0022 - acc: 0.9992 - val_loss: 0.0380 - val_acc: 0.9919\n",
      "Epoch 55/200\n",
      "60000/60000 [==============================] - 32s 533us/step - loss: 0.0022 - acc: 0.9993 - val_loss: 0.0453 - val_acc: 0.9922\n",
      "Epoch 56/200\n",
      "60000/60000 [==============================] - 32s 534us/step - loss: 0.0020 - acc: 0.9995 - val_loss: 0.0476 - val_acc: 0.9918\n",
      "Epoch 57/200\n",
      "60000/60000 [==============================] - 32s 533us/step - loss: 0.0027 - acc: 0.9990 - val_loss: 0.0472 - val_acc: 0.9907\n",
      "Epoch 58/200\n",
      "60000/60000 [==============================] - 32s 533us/step - loss: 0.0034 - acc: 0.9991 - val_loss: 0.0479 - val_acc: 0.9918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "60000/60000 [==============================] - 32s 532us/step - loss: 0.0024 - acc: 0.9993 - val_loss: 0.0450 - val_acc: 0.9916\n",
      "Epoch 60/200\n",
      "60000/60000 [==============================] - 32s 535us/step - loss: 0.0052 - acc: 0.9984 - val_loss: 0.0589 - val_acc: 0.9875\n",
      "Epoch 61/200\n",
      "60000/60000 [==============================] - 32s 533us/step - loss: 0.0035 - acc: 0.9988 - val_loss: 0.0448 - val_acc: 0.9916\n",
      "Epoch 62/200\n",
      "60000/60000 [==============================] - 32s 534us/step - loss: 0.0042 - acc: 0.9985 - val_loss: 0.0447 - val_acc: 0.9922\n",
      "Epoch 63/200\n",
      "60000/60000 [==============================] - 32s 535us/step - loss: 0.0028 - acc: 0.9990 - val_loss: 0.0437 - val_acc: 0.9923\n",
      "Epoch 64/200\n",
      "60000/60000 [==============================] - 32s 536us/step - loss: 0.0039 - acc: 0.9989 - val_loss: 0.0539 - val_acc: 0.9911\n",
      "Epoch 65/200\n",
      "60000/60000 [==============================] - 32s 534us/step - loss: 0.0021 - acc: 0.9994 - val_loss: 0.0492 - val_acc: 0.9922\n",
      "Epoch 66/200\n",
      "60000/60000 [==============================] - 32s 531us/step - loss: 0.0044 - acc: 0.9988 - val_loss: 0.0449 - val_acc: 0.9922\n",
      "Epoch 67/200\n",
      "60000/60000 [==============================] - 32s 532us/step - loss: 0.0019 - acc: 0.9994 - val_loss: 0.0463 - val_acc: 0.9923\n",
      "Epoch 68/200\n",
      "60000/60000 [==============================] - 32s 533us/step - loss: 0.0042 - acc: 0.9987 - val_loss: 0.0525 - val_acc: 0.9902\n",
      "Epoch 69/200\n",
      "60000/60000 [==============================] - 32s 532us/step - loss: 0.0033 - acc: 0.9992 - val_loss: 0.0443 - val_acc: 0.9906\n",
      "Epoch 70/200\n",
      "60000/60000 [==============================] - 32s 534us/step - loss: 0.0021 - acc: 0.9993 - val_loss: 0.0454 - val_acc: 0.9918\n",
      "Epoch 71/200\n",
      "60000/60000 [==============================] - 32s 535us/step - loss: 0.0030 - acc: 0.9992 - val_loss: 0.0431 - val_acc: 0.9911\n",
      "Epoch 72/200\n",
      "60000/60000 [==============================] - 32s 531us/step - loss: 0.0030 - acc: 0.9991 - val_loss: 0.0474 - val_acc: 0.9916\n",
      "Epoch 73/200\n",
      "60000/60000 [==============================] - 32s 534us/step - loss: 0.0024 - acc: 0.9993 - val_loss: 0.0484 - val_acc: 0.9908\n",
      "Epoch 74/200\n",
      "60000/60000 [==============================] - 32s 530us/step - loss: 0.0022 - acc: 0.9993 - val_loss: 0.0503 - val_acc: 0.9904\n",
      "Epoch 75/200\n",
      "60000/60000 [==============================] - 32s 534us/step - loss: 0.0016 - acc: 0.9995 - val_loss: 0.0514 - val_acc: 0.9914\n",
      "Epoch 76/200\n",
      "60000/60000 [==============================] - 32s 534us/step - loss: 0.0022 - acc: 0.9994 - val_loss: 0.0458 - val_acc: 0.9923\n",
      "Epoch 77/200\n",
      "60000/60000 [==============================] - 32s 535us/step - loss: 0.0028 - acc: 0.9990 - val_loss: 0.0477 - val_acc: 0.9920\n",
      "Epoch 78/200\n",
      "60000/60000 [==============================] - 32s 536us/step - loss: 0.0016 - acc: 0.9994 - val_loss: 0.0486 - val_acc: 0.9917\n",
      "Epoch 79/200\n",
      "60000/60000 [==============================] - 32s 538us/step - loss: 0.0021 - acc: 0.9994 - val_loss: 0.0437 - val_acc: 0.9915\n",
      "Epoch 80/200\n",
      "60000/60000 [==============================] - 32s 538us/step - loss: 0.0046 - acc: 0.9988 - val_loss: 0.0424 - val_acc: 0.9929\n",
      "Epoch 81/200\n",
      "60000/60000 [==============================] - 32s 537us/step - loss: 0.0042 - acc: 0.9988 - val_loss: 0.0474 - val_acc: 0.9922\n",
      "Epoch 82/200\n",
      "60000/60000 [==============================] - 32s 538us/step - loss: 0.0014 - acc: 0.9996 - val_loss: 0.0443 - val_acc: 0.9927\n",
      "Epoch 83/200\n",
      "60000/60000 [==============================] - 32s 537us/step - loss: 0.0011 - acc: 0.9996 - val_loss: 0.0479 - val_acc: 0.9925\n",
      "Epoch 84/200\n",
      "60000/60000 [==============================] - 32s 537us/step - loss: 7.7953e-04 - acc: 0.9998 - val_loss: 0.0467 - val_acc: 0.9932\n",
      "Epoch 85/200\n",
      "60000/60000 [==============================] - 32s 537us/step - loss: 5.7523e-04 - acc: 0.9998 - val_loss: 0.0494 - val_acc: 0.9921\n",
      "Epoch 86/200\n",
      "60000/60000 [==============================] - 32s 535us/step - loss: 0.0016 - acc: 0.9995 - val_loss: 0.0490 - val_acc: 0.9917\n",
      "Epoch 87/200\n",
      "60000/60000 [==============================] - 45s 746us/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0455 - val_acc: 0.9934\n",
      "Epoch 88/200\n",
      "60000/60000 [==============================] - 51s 854us/step - loss: 6.2491e-04 - acc: 0.9998 - val_loss: 0.0471 - val_acc: 0.9926\n",
      "Epoch 89/200\n",
      "60000/60000 [==============================] - 51s 852us/step - loss: 5.5981e-04 - acc: 0.9998 - val_loss: 0.0447 - val_acc: 0.9932\n",
      "Epoch 90/200\n",
      "60000/60000 [==============================] - 51s 858us/step - loss: 0.0016 - acc: 0.9995 - val_loss: 0.0581 - val_acc: 0.9907\n",
      "Epoch 91/200\n",
      "60000/60000 [==============================] - 51s 856us/step - loss: 0.0062 - acc: 0.9983 - val_loss: 0.0541 - val_acc: 0.9903\n",
      "Epoch 92/200\n",
      "60000/60000 [==============================] - 51s 853us/step - loss: 0.0032 - acc: 0.9990 - val_loss: 0.0456 - val_acc: 0.9919\n",
      "Epoch 93/200\n",
      "60000/60000 [==============================] - 51s 853us/step - loss: 8.7479e-04 - acc: 0.9996 - val_loss: 0.0441 - val_acc: 0.9915\n",
      "Epoch 94/200\n",
      "60000/60000 [==============================] - 51s 852us/step - loss: 0.0012 - acc: 0.9996 - val_loss: 0.0477 - val_acc: 0.9919\n",
      "Epoch 95/200\n",
      "60000/60000 [==============================] - 51s 852us/step - loss: 0.0014 - acc: 0.9996 - val_loss: 0.0439 - val_acc: 0.9923\n",
      "Epoch 96/200\n",
      "60000/60000 [==============================] - 52s 867us/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0529 - val_acc: 0.9914\n",
      "Epoch 97/200\n",
      "60000/60000 [==============================] - 52s 863us/step - loss: 8.0130e-04 - acc: 0.9998 - val_loss: 0.0459 - val_acc: 0.9922\n",
      "Epoch 98/200\n",
      "60000/60000 [==============================] - 51s 850us/step - loss: 8.8939e-04 - acc: 0.9997 - val_loss: 0.0491 - val_acc: 0.9921\n",
      "Epoch 99/200\n",
      "60000/60000 [==============================] - 51s 849us/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0507 - val_acc: 0.9922\n",
      "Epoch 100/200\n",
      "60000/60000 [==============================] - 51s 856us/step - loss: 0.0024 - acc: 0.9995 - val_loss: 0.0479 - val_acc: 0.9915\n",
      "Epoch 101/200\n",
      "60000/60000 [==============================] - 51s 858us/step - loss: 0.0037 - acc: 0.9990 - val_loss: 0.0523 - val_acc: 0.9912\n",
      "Epoch 102/200\n",
      "60000/60000 [==============================] - 51s 853us/step - loss: 0.0012 - acc: 0.9997 - val_loss: 0.0475 - val_acc: 0.9922\n",
      "Epoch 103/200\n",
      "60000/60000 [==============================] - 51s 857us/step - loss: 0.0016 - acc: 0.9995 - val_loss: 0.0452 - val_acc: 0.9922\n",
      "Epoch 104/200\n",
      "60000/60000 [==============================] - 51s 856us/step - loss: 0.0033 - acc: 0.9990 - val_loss: 0.0489 - val_acc: 0.9919\n",
      "Epoch 105/200\n",
      "60000/60000 [==============================] - 51s 857us/step - loss: 0.0031 - acc: 0.9991 - val_loss: 0.0489 - val_acc: 0.9923\n",
      "Epoch 106/200\n",
      "60000/60000 [==============================] - 52s 861us/step - loss: 0.0031 - acc: 0.9993 - val_loss: 0.0485 - val_acc: 0.9912\n",
      "Epoch 107/200\n",
      "60000/60000 [==============================] - 51s 853us/step - loss: 9.8871e-04 - acc: 0.9998 - val_loss: 0.0467 - val_acc: 0.9925\n",
      "Epoch 108/200\n",
      "60000/60000 [==============================] - 51s 854us/step - loss: 8.5384e-04 - acc: 0.9998 - val_loss: 0.0486 - val_acc: 0.9923\n",
      "Epoch 109/200\n",
      "60000/60000 [==============================] - 51s 856us/step - loss: 7.5026e-04 - acc: 0.9998 - val_loss: 0.0486 - val_acc: 0.9923\n",
      "Epoch 110/200\n",
      "60000/60000 [==============================] - 51s 855us/step - loss: 2.3989e-04 - acc: 0.9999 - val_loss: 0.0494 - val_acc: 0.9925\n",
      "Epoch 111/200\n",
      "60000/60000 [==============================] - 52s 859us/step - loss: 8.5072e-04 - acc: 0.9997 - val_loss: 0.0468 - val_acc: 0.9920\n",
      "Epoch 112/200\n",
      "60000/60000 [==============================] - 51s 858us/step - loss: 6.9171e-04 - acc: 0.9998 - val_loss: 0.0500 - val_acc: 0.9921\n",
      "Epoch 113/200\n",
      "60000/60000 [==============================] - 51s 856us/step - loss: 5.4739e-04 - acc: 0.9998 - val_loss: 0.0520 - val_acc: 0.9925\n",
      "Epoch 114/200\n",
      "60000/60000 [==============================] - 51s 848us/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0462 - val_acc: 0.9919\n",
      "Epoch 115/200\n",
      "60000/60000 [==============================] - 51s 849us/step - loss: 3.6972e-04 - acc: 0.9999 - val_loss: 0.0501 - val_acc: 0.9925\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 51s 855us/step - loss: 0.0012 - acc: 0.9997 - val_loss: 0.0459 - val_acc: 0.9921\n",
      "Epoch 117/200\n",
      "60000/60000 [==============================] - 51s 852us/step - loss: 0.0012 - acc: 0.9996 - val_loss: 0.0509 - val_acc: 0.9916\n",
      "Epoch 118/200\n",
      "60000/60000 [==============================] - 51s 855us/step - loss: 0.0010 - acc: 0.9997 - val_loss: 0.0463 - val_acc: 0.9923\n",
      "Epoch 119/200\n",
      "60000/60000 [==============================] - 51s 849us/step - loss: 0.0010 - acc: 0.9997 - val_loss: 0.0497 - val_acc: 0.9918\n",
      "Epoch 120/200\n",
      "60000/60000 [==============================] - 51s 855us/step - loss: 0.0025 - acc: 0.9994 - val_loss: 0.0534 - val_acc: 0.9914\n",
      "Epoch 121/200\n",
      "60000/60000 [==============================] - 51s 855us/step - loss: 0.0066 - acc: 0.9982 - val_loss: 0.0596 - val_acc: 0.9902\n",
      "Epoch 122/200\n",
      "60000/60000 [==============================] - 51s 857us/step - loss: 0.0036 - acc: 0.9989 - val_loss: 0.0570 - val_acc: 0.9912\n",
      "Epoch 123/200\n",
      "60000/60000 [==============================] - 51s 852us/step - loss: 0.0025 - acc: 0.9993 - val_loss: 0.0521 - val_acc: 0.9911\n",
      "Epoch 124/200\n",
      "60000/60000 [==============================] - 51s 855us/step - loss: 0.0033 - acc: 0.9989 - val_loss: 0.0470 - val_acc: 0.9918\n",
      "Epoch 125/200\n",
      "60000/60000 [==============================] - 51s 852us/step - loss: 0.0057 - acc: 0.9985 - val_loss: 0.0573 - val_acc: 0.9915\n",
      "Epoch 126/200\n",
      "60000/60000 [==============================] - 51s 856us/step - loss: 0.0025 - acc: 0.9993 - val_loss: 0.0479 - val_acc: 0.9917\n",
      "Epoch 127/200\n",
      "60000/60000 [==============================] - 51s 850us/step - loss: 0.0045 - acc: 0.9986 - val_loss: 0.0503 - val_acc: 0.9917\n",
      "Epoch 128/200\n",
      "60000/60000 [==============================] - 51s 857us/step - loss: 0.0021 - acc: 0.9992 - val_loss: 0.0442 - val_acc: 0.9922\n",
      "Epoch 129/200\n",
      "60000/60000 [==============================] - 51s 848us/step - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0500 - val_acc: 0.9906\n",
      "Epoch 130/200\n",
      "60000/60000 [==============================] - 51s 850us/step - loss: 8.6275e-04 - acc: 0.9997 - val_loss: 0.0495 - val_acc: 0.9926\n",
      "Epoch 131/200\n",
      "60000/60000 [==============================] - 51s 854us/step - loss: 4.0432e-04 - acc: 0.9998 - val_loss: 0.0516 - val_acc: 0.9909\n",
      "Epoch 132/200\n",
      "60000/60000 [==============================] - 51s 850us/step - loss: 7.5513e-04 - acc: 0.9998 - val_loss: 0.0487 - val_acc: 0.9922\n",
      "Epoch 133/200\n",
      "60000/60000 [==============================] - 51s 855us/step - loss: 0.0018 - acc: 0.9995 - val_loss: 0.0530 - val_acc: 0.9910\n",
      "Epoch 134/200\n",
      "60000/60000 [==============================] - 51s 852us/step - loss: 0.0012 - acc: 0.9996 - val_loss: 0.0479 - val_acc: 0.9921\n",
      "Epoch 135/200\n",
      "60000/60000 [==============================] - 51s 852us/step - loss: 0.0020 - acc: 0.9996 - val_loss: 0.0496 - val_acc: 0.9921\n",
      "Epoch 136/200\n",
      "60000/60000 [==============================] - 51s 850us/step - loss: 0.0029 - acc: 0.9992 - val_loss: 0.0506 - val_acc: 0.9926\n",
      "Epoch 137/200\n",
      "60000/60000 [==============================] - 52s 862us/step - loss: 0.0017 - acc: 0.9995 - val_loss: 0.0419 - val_acc: 0.9927\n",
      "Epoch 138/200\n",
      "60000/60000 [==============================] - 51s 856us/step - loss: 5.5876e-04 - acc: 0.9999 - val_loss: 0.0516 - val_acc: 0.9917\n",
      "Epoch 139/200\n",
      "60000/60000 [==============================] - 51s 851us/step - loss: 0.0023 - acc: 0.9994 - val_loss: 0.0456 - val_acc: 0.9921\n",
      "Epoch 140/200\n",
      "60000/60000 [==============================] - 51s 853us/step - loss: 8.5718e-04 - acc: 0.9996 - val_loss: 0.0413 - val_acc: 0.9927\n",
      "Epoch 141/200\n",
      "60000/60000 [==============================] - 51s 845us/step - loss: 8.3853e-04 - acc: 0.9997 - val_loss: 0.0424 - val_acc: 0.9925\n",
      "Epoch 142/200\n",
      "60000/60000 [==============================] - 51s 850us/step - loss: 1.7805e-04 - acc: 1.0000 - val_loss: 0.0469 - val_acc: 0.9926\n",
      "Epoch 143/200\n",
      "60000/60000 [==============================] - 51s 857us/step - loss: 2.7570e-04 - acc: 0.9999 - val_loss: 0.0457 - val_acc: 0.9928\n",
      "Epoch 144/200\n",
      "60000/60000 [==============================] - 51s 853us/step - loss: 1.6998e-04 - acc: 0.9999 - val_loss: 0.0467 - val_acc: 0.9926\n",
      "Epoch 145/200\n",
      "60000/60000 [==============================] - 51s 856us/step - loss: 7.7294e-05 - acc: 1.0000 - val_loss: 0.0474 - val_acc: 0.9933\n",
      "Epoch 146/200\n",
      "60000/60000 [==============================] - 51s 852us/step - loss: 5.9090e-05 - acc: 1.0000 - val_loss: 0.0459 - val_acc: 0.9928\n",
      "Epoch 147/200\n",
      "60000/60000 [==============================] - 51s 853us/step - loss: 1.1854e-04 - acc: 1.0000 - val_loss: 0.0525 - val_acc: 0.9912\n",
      "Epoch 148/200\n",
      "60000/60000 [==============================] - 51s 856us/step - loss: 0.0010 - acc: 0.9996 - val_loss: 0.0536 - val_acc: 0.9919\n",
      "Epoch 149/200\n",
      "60000/60000 [==============================] - 51s 853us/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0522 - val_acc: 0.9919\n",
      "Epoch 150/200\n",
      "60000/60000 [==============================] - 51s 854us/step - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0555 - val_acc: 0.9917\n",
      "Epoch 151/200\n",
      "60000/60000 [==============================] - 51s 850us/step - loss: 0.0012 - acc: 0.9996 - val_loss: 0.0553 - val_acc: 0.9923\n",
      "Epoch 152/200\n",
      "60000/60000 [==============================] - 51s 853us/step - loss: 0.0010 - acc: 0.9997 - val_loss: 0.0482 - val_acc: 0.9925\n",
      "Epoch 153/200\n",
      "60000/60000 [==============================] - 51s 853us/step - loss: 6.0506e-04 - acc: 0.9998 - val_loss: 0.0523 - val_acc: 0.9933\n",
      "Epoch 154/200\n",
      "60000/60000 [==============================] - 52s 859us/step - loss: 0.0012 - acc: 0.9997 - val_loss: 0.0485 - val_acc: 0.9932\n",
      "Epoch 155/200\n",
      "60000/60000 [==============================] - 52s 859us/step - loss: 9.2050e-04 - acc: 0.9997 - val_loss: 0.0553 - val_acc: 0.9923\n",
      "Epoch 156/200\n",
      "60000/60000 [==============================] - 51s 853us/step - loss: 0.0014 - acc: 0.9995 - val_loss: 0.0534 - val_acc: 0.9927\n",
      "Epoch 157/200\n",
      "60000/60000 [==============================] - 51s 854us/step - loss: 6.1280e-04 - acc: 0.9998 - val_loss: 0.0479 - val_acc: 0.9927\n",
      "Epoch 158/200\n",
      "60000/60000 [==============================] - 52s 863us/step - loss: 3.2613e-04 - acc: 0.9999 - val_loss: 0.0512 - val_acc: 0.9929\n",
      "Epoch 159/200\n",
      "60000/60000 [==============================] - 52s 862us/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0516 - val_acc: 0.9927\n",
      "Epoch 160/200\n",
      "60000/60000 [==============================] - 51s 857us/step - loss: 9.5615e-04 - acc: 0.9997 - val_loss: 0.0617 - val_acc: 0.9916\n",
      "Epoch 161/200\n",
      "60000/60000 [==============================] - 51s 855us/step - loss: 0.0017 - acc: 0.9995 - val_loss: 0.0562 - val_acc: 0.9922\n",
      "Epoch 162/200\n",
      "60000/60000 [==============================] - 52s 863us/step - loss: 0.0025 - acc: 0.9994 - val_loss: 0.0542 - val_acc: 0.9924\n",
      "Epoch 163/200\n",
      "60000/60000 [==============================] - 52s 859us/step - loss: 0.0016 - acc: 0.9997 - val_loss: 0.0522 - val_acc: 0.9918\n",
      "Epoch 164/200\n",
      "60000/60000 [==============================] - 51s 855us/step - loss: 6.9901e-04 - acc: 0.9998 - val_loss: 0.0537 - val_acc: 0.9922\n",
      "Epoch 165/200\n",
      "60000/60000 [==============================] - 51s 858us/step - loss: 5.7942e-04 - acc: 0.9998 - val_loss: 0.0543 - val_acc: 0.9916\n",
      "Epoch 166/200\n",
      "60000/60000 [==============================] - 52s 860us/step - loss: 3.2698e-04 - acc: 0.9999 - val_loss: 0.0537 - val_acc: 0.9926\n",
      "Epoch 167/200\n",
      "60000/60000 [==============================] - 51s 858us/step - loss: 5.9968e-05 - acc: 1.0000 - val_loss: 0.0527 - val_acc: 0.9924\n",
      "Epoch 168/200\n",
      "60000/60000 [==============================] - 51s 858us/step - loss: 8.1010e-04 - acc: 0.9997 - val_loss: 0.0582 - val_acc: 0.9919\n",
      "Epoch 169/200\n",
      "60000/60000 [==============================] - 51s 857us/step - loss: 0.0012 - acc: 0.9996 - val_loss: 0.0557 - val_acc: 0.9923\n",
      "Epoch 170/200\n",
      "60000/60000 [==============================] - 51s 852us/step - loss: 0.0012 - acc: 0.9997 - val_loss: 0.0586 - val_acc: 0.9916\n",
      "Epoch 171/200\n",
      "60000/60000 [==============================] - 51s 853us/step - loss: 0.0042 - acc: 0.9989 - val_loss: 0.0501 - val_acc: 0.9916\n",
      "Epoch 172/200\n",
      "60000/60000 [==============================] - 51s 856us/step - loss: 0.0033 - acc: 0.9991 - val_loss: 0.0518 - val_acc: 0.9923\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 51s 854us/step - loss: 0.0031 - acc: 0.9993 - val_loss: 0.0470 - val_acc: 0.9924\n",
      "Epoch 174/200\n",
      "60000/60000 [==============================] - 51s 854us/step - loss: 0.0026 - acc: 0.9993 - val_loss: 0.0577 - val_acc: 0.9907\n",
      "Epoch 175/200\n",
      "60000/60000 [==============================] - 51s 855us/step - loss: 0.0029 - acc: 0.9993 - val_loss: 0.0486 - val_acc: 0.9921\n",
      "Epoch 176/200\n",
      "60000/60000 [==============================] - 51s 856us/step - loss: 5.9784e-04 - acc: 0.9998 - val_loss: 0.0487 - val_acc: 0.9926\n",
      "Epoch 177/200\n",
      "60000/60000 [==============================] - 51s 855us/step - loss: 3.4224e-04 - acc: 0.9999 - val_loss: 0.0496 - val_acc: 0.9927\n",
      "Epoch 178/200\n",
      "60000/60000 [==============================] - 51s 857us/step - loss: 2.1469e-04 - acc: 0.9999 - val_loss: 0.0432 - val_acc: 0.9924\n",
      "Epoch 179/200\n",
      "60000/60000 [==============================] - 51s 855us/step - loss: 2.3226e-04 - acc: 0.9999 - val_loss: 0.0460 - val_acc: 0.9929\n",
      "Epoch 180/200\n",
      "60000/60000 [==============================] - 51s 856us/step - loss: 3.2542e-04 - acc: 0.9999 - val_loss: 0.0482 - val_acc: 0.9928\n",
      "Epoch 181/200\n",
      "60000/60000 [==============================] - 51s 856us/step - loss: 6.0906e-05 - acc: 1.0000 - val_loss: 0.0461 - val_acc: 0.9933\n",
      "Epoch 182/200\n",
      "60000/60000 [==============================] - 52s 859us/step - loss: 8.1405e-05 - acc: 1.0000 - val_loss: 0.0454 - val_acc: 0.9937\n",
      "Epoch 183/200\n",
      "60000/60000 [==============================] - 52s 861us/step - loss: 6.2958e-05 - acc: 1.0000 - val_loss: 0.0468 - val_acc: 0.9931\n",
      "Epoch 184/200\n",
      "60000/60000 [==============================] - 52s 868us/step - loss: 3.9258e-05 - acc: 1.0000 - val_loss: 0.0469 - val_acc: 0.9930\n",
      "Epoch 185/200\n",
      "60000/60000 [==============================] - 52s 868us/step - loss: 3.6582e-05 - acc: 1.0000 - val_loss: 0.0470 - val_acc: 0.9934\n",
      "Epoch 186/200\n",
      "60000/60000 [==============================] - 52s 861us/step - loss: 8.5893e-05 - acc: 1.0000 - val_loss: 0.0477 - val_acc: 0.9936\n",
      "Epoch 187/200\n",
      "60000/60000 [==============================] - 51s 856us/step - loss: 6.6782e-05 - acc: 1.0000 - val_loss: 0.0491 - val_acc: 0.9933\n",
      "Epoch 188/200\n",
      "60000/60000 [==============================] - 51s 857us/step - loss: 6.8084e-05 - acc: 1.0000 - val_loss: 0.0457 - val_acc: 0.9936\n",
      "Epoch 189/200\n",
      "60000/60000 [==============================] - 52s 866us/step - loss: 8.2806e-05 - acc: 1.0000 - val_loss: 0.0558 - val_acc: 0.9914\n",
      "Epoch 190/200\n",
      "60000/60000 [==============================] - 52s 862us/step - loss: 1.3701e-04 - acc: 1.0000 - val_loss: 0.0474 - val_acc: 0.9934\n",
      "Epoch 191/200\n",
      "60000/60000 [==============================] - 51s 857us/step - loss: 6.7403e-04 - acc: 0.9998 - val_loss: 0.0490 - val_acc: 0.9927\n",
      "Epoch 192/200\n",
      "60000/60000 [==============================] - 52s 860us/step - loss: 0.0013 - acc: 0.9997 - val_loss: 0.0501 - val_acc: 0.9922\n",
      "Epoch 193/200\n",
      "60000/60000 [==============================] - 51s 853us/step - loss: 4.1088e-04 - acc: 0.9999 - val_loss: 0.0471 - val_acc: 0.9927\n",
      "Epoch 194/200\n",
      "60000/60000 [==============================] - 52s 860us/step - loss: 1.1118e-04 - acc: 1.0000 - val_loss: 0.0498 - val_acc: 0.9927\n",
      "Epoch 195/200\n",
      "60000/60000 [==============================] - 52s 859us/step - loss: 1.6399e-04 - acc: 0.9999 - val_loss: 0.0491 - val_acc: 0.9926\n",
      "Epoch 196/200\n",
      "60000/60000 [==============================] - 52s 859us/step - loss: 4.4220e-04 - acc: 0.9999 - val_loss: 0.0551 - val_acc: 0.9926\n",
      "Epoch 197/200\n",
      "60000/60000 [==============================] - 51s 856us/step - loss: 3.7063e-04 - acc: 0.9999 - val_loss: 0.0495 - val_acc: 0.9931\n",
      "Epoch 198/200\n",
      "60000/60000 [==============================] - 52s 864us/step - loss: 8.9665e-05 - acc: 1.0000 - val_loss: 0.0504 - val_acc: 0.9924\n",
      "Epoch 199/200\n",
      "60000/60000 [==============================] - 51s 855us/step - loss: 2.9055e-04 - acc: 0.9999 - val_loss: 0.0496 - val_acc: 0.9927\n",
      "Epoch 200/200\n",
      "60000/60000 [==============================] - 51s 849us/step - loss: 2.9841e-04 - acc: 0.9999 - val_loss: 0.0528 - val_acc: 0.9924\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the Model\n",
    "#earlyStopping=keras.callbacks.EarlyStopping(monitor='val_acc', min_delta=0, patience=13, verbose=1, mode='auto')\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "#                    callbacks=[earlyStopping],\n",
    "                    validation_data=(x_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5373100588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train acc','val acc'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xl8VOW9+PHPdyY7SSAb+xYQlFUE\nRFwqKC6gFWzdwLW11Xqt17be61XbW2vt/bW2drXaWrXuVtyqUqXS0opLi8oiooDIIpgAQhKSkD2Z\nme/vj+ckDGEyJMBJgPm+X+TFzJlnzvnOmTPne57nOec5oqoYY4wxAIGuDsAYY8yhw5KCMcaYFpYU\njDHGtLCkYIwxpoUlBWOMMS0sKRhjjGlhScGYdhKRR0Xk/9pZdpOInHGg8zGms1lSMMYY08KSgjHG\nmBaWFMwRxWu2uVlEVopIjYj8UUR6ichfRaRKRBaKSE5U+ZkiskpEKkRkkYiMiHrtOBFZ7r3vGSCt\n1bK+KCIrvPf+W0TG7mfM14jIehHZKSLzRKSvN11E5FciskNEKr3PNNp77RwRWe3FtkVE/nu/Vpgx\nrVhSMEeiC4AzgeHAecBfge8C+bht/kYAERkOPA18GygA5gN/EZEUEUkBXgKeAHKB57z54r13PPAw\n8A0gD/gDME9EUjsSqIicDvwEuBjoA2wG5novnwWc6n2OHsAlQJn32h+Bb6hqFjAa+GdHlmtMWywp\nmCPRb1V1u6puAd4C3lXV91W1AXgROM4rdwnwqqr+XVWbgJ8D6cBJwGQgGfi1qjap6vPAkqhlXAP8\nQVXfVdWwqj4GNHjv64jLgIdVdbkX323AiSIyGGgCsoBjAFHVNaq6zXtfEzBSRLJVtVxVl3dwucbE\nZEnBHIm2Rz2ui/E803vcF3dkDoCqRoAioJ/32hbdc8TIzVGPBwH/5TUdVYhIBTDAe19HtI6hGlcb\n6Keq/wTuBe4DtovIAyKS7RW9ADgH2Cwib4jIiR1crjExWVIwiWwrbucOuDZ83I59C7AN6OdNazYw\n6nER8P9UtUfUX4aqPn2AMXTDNUdtAVDVe1R1AjAK14x0szd9iarOAnrimrme7eByjYnJkoJJZM8C\n54rINBFJBv4L1wT0b2AxEAJuFJEkEfkyMCnqvQ8C14nICV6HcDcROVdEsjoYw5+Ar4rIOK8/4se4\n5q5NInK8N/9koAaoB8Jen8dlItLda/baBYQPYD0Y08KSgklYqroWuBz4LVCK65Q+T1UbVbUR+DLw\nFaAc1//w56j3LsX1K9zrvb7eK9vRGP4BfB94AVc7GQrM9l7OxiWfclwTUxmu3wPgCmCTiOwCrvM+\nhzEHTOwmO8YYY5pZTcEYY0wLSwrGGGNaWFIwxhjTwpKCMcaYFkldHUBH5efn6+DBg7s6DGOMOaws\nW7asVFUL9lXusEsKgwcPZunSpV0dhjHGHFZEZPO+S1nzkTHGmCiWFIwxxrTwNSmIyHQRWeuNFX9r\njNd/5Y1Hv0JEPvEGFTPGGNNFfOtTEJEgbnTHM4FiYImIzFPV1c1lVPU7UeX/k91DGndIU1MTxcXF\n1NfXH2DUiSstLY3+/fuTnJzc1aEYY7qQnx3Nk4D1qroRQETmArOA1W2UnwP8YH8WVFxcTFZWFoMH\nD2bPQS1Ne6gqZWVlFBcXU1hY2NXhGGO6kJ/NR/1wwws3K/am7UVEBgGFtHH3KBG5VkSWisjSkpKS\nvV6vr68nLy/PEsJ+EhHy8vKspmWM8TUpxNpDtzX63mzgeVWNOfyvqj6gqhNVdWJBQezTbC0hHBhb\nf8YY8DcpFONuWNKsP+6GIrHMxt0r1zc1DSE+r6wnYqPCGmNMm/xMCkuAYSJS6N0EfTYwr3UhETka\nyMHd1MQ3tY0hdlTV40dOqKio4He/+91+vfecc86hoqL9J13dcccd/PznP993QWOM2Q++JQVVDQE3\nAAuANcCzqrpKRO4UkZlRRecAc9X3Gzs0N48c/MXESwrhcPwbYs2fP58ePXoc9JiMMWZ/+HqdgqrO\nV9XhqjpUVf+fN+12VZ0XVeYOVd3rGgbfYvJhnrfeeisbNmxg3Lhx3HzzzSxatIjTTjuNSy+9lDFj\nxgBw/vnnM2HCBEaNGsUDDzzQ8t7BgwdTWlrKpk2bGDFiBNdccw2jRo3irLPOoq6uLu5yV6xYweTJ\nkxk7dixf+tKXKC8vB+Cee+5h5MiRjB07ltmz3U283njjDcaNG8e4ceM47rjjqKqq8mFNGGMOd4fd\n2Ef78sO/rGL11l17TW8KR2gMRchITYrZAx7PyL7Z/OC8UW2+ftddd/HRRx+xYsUKABYtWsR7773H\nRx991HKK58MPP0xubi51dXUcf/zxXHDBBeTl5e0xn3Xr1vH000/z4IMPcvHFF/PCCy9w+eVt32Xx\nyiuv5Le//S1Tpkzh9ttv54c//CG//vWvueuuu/j0009JTU1taZr6+c9/zn333cfJJ59MdXU1aWlp\nHVwLxphEYMNc+GTSpEl7nPN/zz33cOyxxzJ58mSKiopYt27dXu8pLCxk3LhxAEyYMIFNmza1Of/K\nykoqKiqYMmUKAFdddRVvvvkmAGPHjuWyyy7jySefJCnJ5f2TTz6Zm266iXvuuYeKioqW6cYYE+2I\n2zO0dURfVt3Aloo6RvTJJjnofy7s1q1by+NFixaxcOFCFi9eTEZGBlOnTo15TUBqamrL42AwuM/m\no7a8+uqrvPnmm8ybN48f/ehHrFq1iltvvZVzzz2X+fPnM3nyZBYuXMgxxxyzX/M3xhy5rKZwEGRl\nZcVto6+srCQnJ4eMjAw+/vhj3nnnnQNeZvfu3cnJyeGtt94C4IknnmDKlClEIhGKioo47bTT+NnP\nfkZFRQXV1dVs2LCBMWPGcMsttzBx4kQ+/vjjA47BGHPkOeJqCm1pvjbLj3Oc8vLyOPnkkxk9ejQz\nZszg3HPP3eP16dOnc//99zN27FiOPvpoJk+efFCW+9hjj3HddddRW1vLkCFDeOSRRwiHw1x++eVU\nVlaiqnznO9+hR48efP/73+f1118nGAwycuRIZsyYcVBiMMYcWcT3M0EPsokTJ2rrm+ysWbOGESNG\nxH3fzppGistrOaZ3FilJQT9DPGy1Zz0aYw5PIrJMVSfuq1zCNR8dXinQGGM6V8IkBfHv2jVjjDli\nJE5S6OoAjDHmMJAwSaGZVRSMMaZtCZcUjDHGtC1hkkJLl4JVFYwxpk0JkxT87GmeOnUqCxYs2GPa\nr3/9a66//vq478vMzOzQdGOM8VvCJAU/Tz6aM2cOc+fO3WPa3LlzmTNnjg9LM8YY/yRMUvDThRde\nyCuvvEJDQwMAmzZtYuvWrZxyyilUV1czbdo0xo8fz5gxY3j55Zf3axmbN29m2rRpjB07lmnTpvHZ\nZ58B8NxzzzF69GiOPfZYTj31VABWrVrFpEmTGDduHGPHjo05+J4xxsRy5A1z8ddb4fMP95qcEYkw\npClCakowqimpnXqPgRl3tflyXl4ekyZN4rXXXmPWrFnMnTuXSy65BBEhLS2NF198kezsbEpLS5k8\neTIzZ87s8D2Rb7jhBq688kquuuoqHn74YW688UZeeukl7rzzThYsWEC/fv1ahsm+//77+da3vsVl\nl11GY2PjPm/0Y4wxzaymcJBENyFFNx2pKt/97ncZO3YsZ5xxBlu2bGH79u0dnv/ixYu59NJLAbji\niit4++23ATck9le+8hUefPDBlp3/iSeeyI9//GN++tOfsnnzZtLT0w/GRzTGJIAjr6bQxhF9XX0T\nn5bWMLQgk26pB/9jn3/++dx0000sX76curo6xo8fD8BTTz1FSUkJy5YtIzk5mcGDB8ccNrujmmsa\n999/P++++y6vvvoq48aNY8WKFVx66aWccMIJvPrqq5x99tk89NBDnH766Qe8TGPMkS9hagp+j3KR\nmZnJ1KlTufrqq/foYK6srKRnz54kJyfz+uuvs3nz5v2a/0knndRSE3nqqac45ZRTANiwYQMnnHAC\nd955J/n5+RQVFbFx40aGDBnCjTfeyMyZM1m5cuWBf0BjTEI48moKbfFz7GzPnDlz+PKXv7zHmUiX\nXXYZ5513HhMnTmTcuHHturFNbW0t/fv3b3nefMe0q6++mrvvvpuCggIeeeQRAG6++WbWrVuHqjJt\n2jSOPfZY7rrrLp588kmSk5Pp3bs3t99++8H/sMaYI5KvQ2eLyHTgN0AQeEhV92rbEZGLgTtwB/Ef\nqOql8ea5v0Nn1zSE2FBSTWF+N7LSkjv0ORKFDZ1tzJGrvUNn+1ZTEJEgcB9wJlAMLBGReaq6OqrM\nMOA24GRVLReRnn7FY4wxZt/87FOYBKxX1Y2q2gjMBWa1KnMNcJ+qlgOo6g6/grGRs40xZt/8TAr9\ngKKo58XetGjDgeEi8i8RecdrbtqLiFwrIktFZGlJSUnMhe2zGcyyQlyH2x34jDH+8DMpxLo6q/We\nJwkYBkwF5gAPiUiPvd6k+oCqTlTViQUFBXvNNC0tjbKysrg7NrufQttUlbKyMtLS0ro6FGNMF/Pz\n7KNiYEDU8/7A1hhl3lHVJuBTEVmLSxJLOrKg/v37U1xcTFu1CICmcITtuxoIlaWQnmL3aG4tLS1t\njzOejDGJyc+ksAQYJiKFwBZgNtD6zKKXcDWER0UkH9ectLGjC0pOTqawsDBumY8/38U1T77F7y8b\nz4wRfTq6CGOMSQi+NR+pagi4AVgArAGeVdVVInKniMz0ii0AykRkNfA6cLOqlvkRT8C7TiFiTefG\nGNMmXy9eU9X5wPxW026PeqzATd6fr5qTQtg6VI0xpk0JM8xFoOWCZksKxhjTloRJCkEvK4St/cgY\nY9qUMEnB+hSMMWbfEicpeDWFiGUFY4xpU+IkBa9PIWJ9CsYY06YESgp29pExxuxLwiUFaz0yxpi2\nJVBScP9bn4IxxrQtYZJC8ymp1qdgjDFtS5ik0Hyje7tOwRhj2pYwSaG5pmAVBWOMaVvCJIXmPgU7\n+8gYY9qWQEnB+hSMMWZfEi8pWJ+CMca0KWGSwu6zj7o4EGOMOYQlTFJo6VOwrGCMMW1KmKQgIojY\n/RSMMSaehEkK4PoVrKJgjDFtS6ikEBSxU1KNMSYOX5OCiEwXkbUisl5Ebo3x+ldEpEREVnh/X/c3\nHjsl1Rhj4knya8YiEgTuA84EioElIjJPVVe3KvqMqt7gVxzRggGxU1KNMSYOP2sKk4D1qrpRVRuB\nucAsH5e3T9anYIwx8fmZFPoBRVHPi71prV0gIitF5HkRGeBjPATETkk1xph4/EwKEmNa6z3yX4DB\nqjoWWAg8FnNGIteKyFIRWVpSUrLfAQUCYqekGmNMHH4mhWIg+si/P7A1uoCqlqlqg/f0QWBCrBmp\n6gOqOlFVJxYUFOx3QHb2kTHGxOdnUlgCDBORQhFJAWYD86ILiEifqKczgTU+xoNYn4IxxsTl29lH\nqhoSkRuABUAQeFhVV4nIncBSVZ0H3CgiM4EQsBP4il/xAAQDNiCeMcbE41tSAFDV+cD8VtNuj3p8\nG3CbnzFEc2cfWVIwxpi2JNQVzQERwpGujsIYYw5diZUUAjYgnjHGxJNYScHOPjLGmLgSKikE7ewj\nY4yJK6GSgoidfWSMMfEkVFIIBuzsI2OMiSehkoI7+8iSgjHGtCXhkoLlBGOMaVtiJQU7JdUYY+JK\nqKRgA+IZY0x8CZUUbEA8Y4yJL6GSgt2O0xhj4kuopBAQ7JRUY4yJI8GSgp2Saowx8SRcUrCKgjHG\ntC2hkkIwYGcfGWNMPAmVFMT6FIwxJq6ESgp29pExxsSXUEnBhrkwxpj4Ei4p2NlHxhjTNl+TgohM\nF5G1IrJeRG6NU+5CEVERmehnPHadgjHGxOdbUhCRIHAfMAMYCcwRkZExymUBNwLv+hVLM7ufgjHG\nxOdnTWESsF5VN6pqIzAXmBWj3I+AnwH1PsYCWJ+CMcbsi59JoR9QFPW82JvWQkSOAwao6ivxZiQi\n14rIUhFZWlJSst8BBezsI2OMicvPpCAxprXskUUkAPwK+K99zUhVH1DViao6saCgYL8Dsj4FY4yJ\nz8+kUAwMiHreH9ga9TwLGA0sEpFNwGRgnp+dzXY/BWOMic/PpLAEGCYihSKSAswG5jW/qKqVqpqv\nqoNVdTDwDjBTVZf6FZCIEIn4NXdjjDn8+ZYUVDUE3AAsANYAz6rqKhG5U0Rm+rXceKz5yBhj4kvy\nc+aqOh+Y32ra7W2UnepnLGCnpBpjzL4k1BXNdjtOY4yJL6GSQjCAnZJqjDFxJFRScBevWVIwxpi2\nJFxSsAHxjDGmbe1KCiLyLRHJFuePIrJcRM7yO7iDzW7HaYwx8bW3pnC1qu4CzgIKgK8Cd/kWlU+C\nAeziNWOMiaO9SaF5yIpzgEdU9QNiD2NxSLM+BWOMia+9SWGZiPwNlxQWeMNdH3bXBrsB8bo6CmOM\nOXS19+K1rwHjgI2qWisiubgmpMOKXdFsjDHxtbemcCKwVlUrRORy4H+BSv/C8ocNiGeMMfG1Nyn8\nHqgVkWOB/wE2A4/7FpVPxDv7SC0xGGNMTO1NCiF1e9JZwG9U9Te4oa8PK8GA6xu3SxWMMSa29vYp\nVInIbcAVwBe8+y8n+xeWP7ycQESV4OF38pQxxviuvTWFS4AG3PUKn+Nuq3m3b1H5JOBlBbuq2Rhj\nYmtXUvASwVNAdxH5IlCvqoddn0JAXFKwLgVjjImtvcNcXAy8B1wEXAy8KyIX+hmYH4JeUrAzkIwx\nJrb29il8DzheVXcAiEgBsBB43q/A/CBRfQrGGGP21t4+hUBzQvCUdeC9h4yWs4+sT8EYY2Jqb03h\nNRFZADztPb+EVrfZPBw09ylYTjDGmNjalRRU9WYRuQA4GTcQ3gOq+qKvkfkg0HKdgmUFY4yJpb01\nBVT1BeCFjsxcRKYDvwGCwEOqeler168DvgmEgWrgWlVd3ZFldETLdQpWVTDGmJjiJgURqQJi7UEF\nUFXNjvPeIHAfcCZQDCwRkXmtdvp/UtX7vfIzgV8C0zv2EdovaM1HxhgTV9ykoKoHMpTFJGC9qm4E\nEJG5uGEyWpKCd+OeZt2InYAOmoCdkmqMMXG1u/loP/QDiqKeFwMntC4kIt8EbgJSgNNjzUhErgWu\nBRg4cOB+ByTWfGSMMXH5eVpprMGF9tobq+p9qjoUuAU3JPfeb1J9QFUnqurEgoKC/Q4oaB3NxhgT\nl59JoRgYEPW8P7A1Tvm5wPk+xmOnpBpjzD74mRSWAMNEpFBEUoDZwLzoAiIyLOrpucA6H+OxAfGM\nMWYffOtTUNWQiNwALMCdkvqwqq4SkTuBpao6D7hBRM4AmoBy4Cq/4oHdp6TaTXaMMSY2PzuaUdX5\ntLryWVVvj3r8LT+X35oNiGeMMfEdduMXHQhp7lOIdHEgxhhziEqopGBnHxljTHwJlRQCNnS2McbE\nlVhJwc4+MsaYuBIrKdh1CsYYE1dCJYXdA+JZVjDGmFgSKinY0NnGGBNfYiWFgF2nYIwx8SRWUvCa\njywnGGNMbAmVFILep7U+BWOMiS2hkkLzFc12SqoxxsSWUEkhaM1HxhgTV0IlhYDVFIwxJq7ESgrW\np2CMMXElVlKwi9eMMSauhEoKu0dJ7eJAjDHmEJVQSaH5imbrUzDGmNgSLClY85ExxsRjScEYY0wL\nX5OCiEwXkbUisl5Ebo3x+k0islpEVorIP0RkkJ/xBOx2nMYYE5dvSUFEgsB9wAxgJDBHREa2KvY+\nMFFVxwLPAz/zKx7YfUqqDYhnjDGx+VlTmASsV9WNqtoIzAVmRRdQ1ddVtdZ7+g7Q38d4ogbEs6Rg\njDGx+JkU+gFFUc+LvWlt+RrwVx/jaTklNWzNR8YYE1OSj/OWGNNiHqKLyOXARGBKG69fC1wLMHDg\nwP0PqPkmO1ZTMMaYmPysKRQDA6Ke9we2ti4kImcA3wNmqmpDrBmp6gOqOlFVJxYUFOx3QHY7TmOM\nic/PpLAEGCYihSKSAswG5kUXEJHjgD/gEsIOH2MBos8+sqRgjDGx+JYUVDUE3AAsANYAz6rqKhG5\nU0RmesXuBjKB50RkhYjMa2N2B8Xu23H6uRRjjDl8+dmngKrOB+a3mnZ71OMz/Fx+a83DXNjZR8YY\nE1tCXdG8e0A8SwrGGBNLQiWF3TfZ6eJAjDHmEJWQScFqCsYYE1uCJQX3v519ZIwxsSVUUrCb7Bhj\nTHwJlRSkuU/Bmo+MMSamxEkKyx+He8aTGgjbKanGGNOGxEkKTfWwcwM9pNZux2mMMW1InKSQngNA\njtRYn4IxxrQhQZOCZQVjjIkl8ZJCoMZOSTXGmDYkUFLoAUB3qbazj4wxpg0JlBRcTSEvUENdY7iL\ngzHGmENT4iSFtO6AMCCtgc921u6zuDHGJKLESQqBIKR1p29qHZtKa7o6GmOMOSQlTlIASM+hIKme\nrZX11DdZE5IxxrSWcEkhJ1ANwOYya0IyxpjWEi4pZEZcUvjUmpCMMWYvCZYUepAWqgRgc5klBWOM\naS3BkkIOwfoK8rqlsMmSgjHG7MXXpCAi00VkrYisF5FbY7x+qogsF5GQiFzoZyyAu1ahvoLBuWnW\nfGSMMTH4lhREJAjcB8wARgJzRGRkq2KfAV8B/uRXHHtIzwGNcHQubCq1jmZjjGnNz5rCJGC9qm5U\n1UZgLjAruoCqblLVlUDExzh2865qPjorxOe76u3KZmOMacXPpNAPKIp6XuxN6zARuVZElorI0pKS\nkv2PyEsKw7uHAFi1tXL/52WMMUcgP5OCxJi2XyPRqeoDqjpRVScWFBTsf0ReUhiV42oISzeX7/+8\njDHmCORnUigGBkQ97w9s9XF5++YlhWxqGJLfjaWbdnZpOMYYc6jxMyksAYaJSKGIpACzgXk+Lm/f\nvKRAXTkTB+ewdHO53VvBGGOi+JYUVDUE3AAsANYAz6rqKhG5U0RmAojI8SJSDFwE/EFEVvkVDwBp\n7p4KLinkUlHbxMbSal8XaYwxh5MkP2euqvOB+a2m3R71eAmuWalzJKVASibU7uT4kbkALNlUzlE9\nszothAPSWAO7tkH+UV0diTHmCJVYVzQD5AyGsvUMzssgPzOVRWt3dHVE7ffv38IDUyAc6upIjDFH\nqMRLCj1HwI41iAgXT+zP31ZvP3yubi79BBqrYVdxV0dijDlCJWZSqCyC+l189eRCkoMBHnhzY1dH\n1T4Vn7n/yzd3bRzGmCNWAiaFUe7/HWsoyErlogn9eWFZMdsq67o2rvZoTgoVlhSMMf5IwKQwwv2/\nYzUA100ZCgJ3v7a2C4Nqh6Y6qN7uHltNwSSypjpY/oQ78cIcdImXFLoPcGcg7VgNL3+TARue5uun\nFPLn97fwQVFFV0fXtsqofoS2agofPAObF3dOPG2pq4BXvgPVBzAcSVdoqnPrr6m+qyPpuPpd8OgX\n4ZkrYNvKPV+rK4fGI2zwx7d/BfNugD9d0r7PpgrvPwVblrvt8vWfwNYVe5crXQc1ZQc/3sNM4iWF\nQMDVFj54Bt5/Ehb9hOtPHUh+Ziq3/vnDQ/fezc21g+RusWsKjbXwlxvhtVvaP8+GKqjyah9b34dl\njx14nO8/CUsfhiUP7f3azk8h3HTgy/DD4nvhxWvhoTOgbENXR9N+4RA8/1XY/G/Y+IY7O235E+61\nUAM8cBo8ei5EOjDmpPp0QWftTqj63MW8+D544ksukW19f+/lL/opvPlzqCja87XqEvj3vVAwAja9\nDQ+eBu/c73bm4ZDb8a96CVY+C5++BTWlMP9mePl6V/ZXo+CNu9w6iz4AqCuHB0+Hx847+Gf3qcJf\nvg0rn9t32bpy99mrPt/7tfpd/n03UXy9TuGQ1XMEFC+B1O5QU0Lmpr/zswsnc/WjS7nzldX8+Etj\nujrCvTXXDgZOhu0f7f36prchVA/bPoCST6Bg+L7n+fI3oeg9+NYH8Ndbofg9OPocyNzP8aVU4X1v\nh7TiTzDlFpeEAYqXwUPTYNBJcPET0C3PTa8rhxeugWNnw5g4t9SoKILN/3JNaBO+CmnZ+xdjLJEI\nLHsc8o92Z3b96WK47l+QnLZnubIN8PQcmPZ9GHGe+7zbV7lmjAGTYOkf4dM34dxfQrf8/YulsRbW\nzIP1C+GU70CvUbBrK2T2BhFY93foe5z7jnZ+CvP+Eza9Bef9Bkae73Z2825wCT+YDOWfur+Vc+Go\nM0CCbt2HQ1C1DZJSYfXLbtsZcxH89Rb4fCVc9jzkDXXXxZSsgX4TIK07LH3E/X4GTm7/Z9q5EeZe\nDju8a1PTukN9JfQc6XZ+xUvh0rnw5t3QfxJoGBb92JVddBdc8gT0HuMOOJq380uegJKPXeJ47Rb4\n2/9CSoabbywn/Adk93Gx9BkHr3wbXr0JUrNhyFTYuhwadrkYlz0Ck65x74tEdm/D++vjV9w8Vz7j\ntpOcQS5h15ZBdl9XpqEaJABPXwqf/RtW/dn9Tup2QrcCt+0v/CHM+Gn838lBkJhJofdY9/8FD7mm\njqWPcPqVs7huylDuf2MD/Xqk883TDrELxCo+g0AyDDgBNvzDNXckp+9+ff3fISkNwo3w0fNw2nf3\nnoeq27EAVO+Aj1+FSMj9GIvecdM/eQ3GX7F3+dbKNrgdV1Kq2ynW74KCo90PtXAKfPqG21kNmeLK\n/+OH7gdYvBQeOh0ufRZyCt2R4qa34LPF7gfTY+DuZWx8wy2j6F3312ztX+HsH7v18PmHkDsUTvse\nBJNczGv/Cv2Ph9RMV/tJyXAxLv6d++HnFsLZP3E/zrIN0FQLlZ/BhY+4HdaTX3ZNFKfd5pLWyudg\n9JfdEWfpWnjxOrejfuf3bocL7vqX8k3u8ecfwoUPuyvoX7vVLSMQhIw86HMs9B0P6/4Gu7a4mtPO\njZDVB0bOcomlapvbQWx8A0adD+89AENOczvpJQ9Bdn8YfyX869duJz/zt+45wJy58MLXYMFtkJQO\nA09y28T8/4FQHWT2gitehBe+7nb+0f72fbfc1Ex4eDqk93CnQQMMnwGnfNvtTJO7wVdfdcmpWXWJ\nW1d5R0HNDve+yi3Q8xh46Xq3vs64w23D21bAiJkusX6+Eh46E/5wKgSSYM1f3PxGzoIzfgjPXw3P\nXune11QLGbnue8kf5v5GnAdz7ZSyAAAXzElEQVSffwQfPO0SwpCpUHAMBFNcgt++ym1346/cc1v+\nbDGseAoQePd+99s55otuHgvvgA+fc/E37IIL/gjDz3KfccWTLnGPu9RtR+GQa4pu2OXWc6jRfX/b\nP3JNuYNPcb+FnMHu/c9c7n4zW1dApMktUxXWvurWvao7GHjn93Df8Xt+PwMmQ347DvYOkGgnVEcO\npokTJ+rSpUsPbCZNda7KOugkV1Vb9GP42kJCfSfw3899wEsrtnLjtGHcdKbPX0DVdrehZvbcd9nn\nvup+TFNvgz9fA998z+2EwW1I94xzR7qhencEOeYCV2Oo3u52RjU73E7rnJ+7I41/3QN//77bSVRv\ndz/I9FzoPxHmPO3e+9QF7sd71v+5jTy7n9vRvfQf7sgzlqR0+PZK+O1EdxTUbzykZrkf3tk/cTvr\nuZe67yCY5HYk037gjvhyBrkfcP5Rrhb3zn3ux91zJIycCcOnw4417vNrBBDXR1T5mftxTfsB/Pse\nV1tJzXafu3mnDW4H2WsUrFvgNUt4274E3Ge/aY276v2Fr7smiDEXuh1z1dbdR7cn3eh2JrVl0GsM\nnHCt2xm883sYfQEMPd3VJup2utiT0tw0DbumjC3LIdzgxuHqOcp9/zmDXc215GN3FHvmnZDVGx6Z\n4ZYzfDps+KdbzrGXwsbX3Y7nqDNcDaF7q0EBwiFXg1g5F74y38Xx3FfgqNPhw+fduhdxiTSQ5BJ3\nJATvPgDj5rhayTOXuUR19Ay3Q198r3uu6uYXqoM5z0D/CfDJ39zOu7HK7bwjrZoIJQCX/xmGnhZ7\nm/ngGfjgT27bLHoPNi6CL/7SbTd15TD3Mrf+p9/ltpGDobHWrfM+Y+Glb7pt4prXIaWbq3U01rjf\n5fZVblsZc6Gr/YYbvJ13xP0WIiF37VBryd3cAcBniwGFix6DmhKY/9/uoGDIFLfu3/m9S+wTrnLl\nBkyGEV9020nRe+5AoHqH+/zHnNv2QVo7iMgyVZ24z3IJmRSi1ZXDH6a4H9xFjxGWJG57J8iry9bz\n4KhVnHTRd1y5f/4IJv8H5A45OMttqIb7TgAUrn/HNYdUFLlqZkWROwo59WbXBADw4DR3BDf1u/Dw\nWXDpc+7oJdzkjqIfPdf9qFIy4aXr3I8zf5iretbudPNvrHYb+fS73E46PddrMrjZ7VSz+8Hyx+DK\nl+HZq9yOLdwIg0521de8o9yG+a/fwORvwgnfcBt2crrb0bx5tytz0g2uzLJH3fSqbdBjkEtkyWnu\n8y24ze24R86C4We7I/qFP3BHQp9/6I4Kx18FM362dzPOJwtcx/uI89wP990H3GdoNvl6KFvvOg6/\n+CuXOJpq3I+0ed0vvtfFnjPYNUscc+7uJoOaMneEv+5vLrGd+t8uaSWlwtcWuiaGkrUuCQSCMbap\nClj+OOzcAF/4rz1rP/W73FF077EuATWLRFz53KG7myvKNrhraoZMdc2CpevcMqu3u6Pjo6a1vZNQ\ndTuh1gcc6xfCi/8B03/S/maIcJM7kt+x2tVKBp7oalNVn7uj8s8/hN6j4fhroGydW9/5w11iK3rP\nxXD0jPYtqytEIu6gKav33q9VbnF9ETUlrnZw0o3uN7bqRe+AQ1xTWrcClyyDKe7zZvVxBz1F77m/\nyde777WxxiWeZg3V7juMnuYTSwod8fmHrgobctcqRL5wM++/v4QJ1YtY2vdyxg8fSGDRj10V/ooX\nY/8Qm+rhuatcW3LeMNeRllvojrL7jncbSLQF33M7JgnAmIvdTnvZo+4IJKuvO/odMhVO/77b0d47\n0f2wTvse/OJoOOk/ofexsOC7boNGXN9Aj4Hu8+Qd5ZpNotVXurNUmpsNZv3OHYE/e5WrgTTVwuMz\n3WsZ+XDVPHjrF+4HMO5S+OjPrszI8+GiR9t/1FK/a3ezRHvUVbidfu/R7SsPbge66S334zzm3Pa/\nL57o5jNViIT3/h4PR/GaBduyfbXbDqbc4tZB7U7XnFZT4naKJ93Y/u/3cLNrq+sDyC3s6kgOiCWF\njtq+2nWorfu7a58EKpIKSGuqIBxIJS01hWD9Tjj3F+5IIX+4q+o3H9X98//ckXJSuksug05x7c81\nJe6IdOCJcNwVrilhzTz3gxp/pTtCWHyvq0IedzlM+R/XHPD+U/CXb+1ZFZ92O5xyE/xq9O6hLvoe\nB5O+4arBvUbt+3OGGt3RXLjRJZXoTrRwk2uPzhvmjvbTc7yjqBLI6uXO5lj+OJxzt2tvNsYcNiwp\n7K9wE7zomkV0yq3ovccT0BCzwz/i7pQ/MCAcdb1AUrqrcvYe4zo3R18AM+5yVc5eo9yR+cevuuSw\n+uXdHZEAg78AlzzpmiSWPuKaUPKG7hlL1XbXJllZBMkZMOpLrqOtuT20vsI1+8RqwjDGmCiWFA6W\nN++mqnQrd8nVNO1YR6R4GWsjA5g9qIozcrbRU8uQovcAdacxNp9q2VokAluWulPqcgtdE8wBdBoZ\nY0xHWFLwydaKOn63aD0vvb+V6oYQw3tlcvygHI7tn8WXJgwiOZh41wMaYw59lhR8VtMQ4pWVW3lh\n2RbWbq+isq6JYT0zmTG6NwNyMzhnTB+6pR4BnZLGmCOCJYVOpKosXLODn772MRtLqokoZKUmMX5Q\nDoPyMjihMI+ThuaR0y2FSEQRAbGmI2NMJ7Kk0EXCEeWD4gqefvcz1m6vYmNJDdUNIUSgf04623c1\nkJWaxIlD8zj5qHxG9c2me3oy3dOTyU5LJhCwZGGMOfjamxSsfeMgCwaE8QNzGD8wB4BQOMLKLZW8\nva6Ujz/fxfRR6ZRWN/Kv9aW8snLbHu9NTw5yVM9MstKS6JmVyklD80lLcWcW9UhPpqYhhIhw8lF5\n1DSEKa1uYGSf7JiJJBR2A6AlWR+HMaYDfE0KIjId+A0QBB5S1btavZ4KPA5MAMqAS1R1k58xdbak\nYGCPJNFMVdlQUs3msloqapuoqGuiuLyW9TuqqWsM8/b6Ul5asTXmPIMBIRxxNbwBuemMG5BDbkYy\nPTJSSEsOsn1XPS+v2EJ1Q4gBuRl0T08mORggHFFCEWVQbgZf/0IhY/v3QFVZWVzJqx9u47OyWgbl\nZ3DKUflMKsyltiFM9/SO1V5C4QgriioY1jOL7hnJqGrMpjI/mtEaQmF27Gogt1vKfvXnqCrPLS0G\ngS8f1++wSahV9U3cvWAt/XPSueqkwaQmuQOJUDjCorUl5HRLYcKgHJq8AwU7GcJpa9tMdL41H4lI\nEPgEOBMoBpYAc1R1dVSZ64GxqnqdiMwGvqSql8Sb76HefHSwRCLKxtIaQFGFiromuqUkUd0Q4o1P\ndpCTkUL39GReWbmNzWU1lNc2UVnnLnRLCghnj3Id3pvLaqiqDxGKREgKBAgEhPc3l1PVEKJfj3RE\noLi8jqSAMDA3g+LyOhrDu4dZ7pWdytThPemekUx6cpD0lCDJwQApQSGiULSzls07aymtbmBoQSbL\nN5ezsbSGpICQ2y2FsppGhvXMJD8zlfU7qhndL5ustGReXbmNEX2zGde/Oy9/sJX05CCj+nZnVN9s\n6prCFO2spSmsZKcl0at7Gt1SguR0SyGvWyql1Q1srahjZ00jw3tl0ad7Gut2VPP44s2UVjcAcObI\nXnztlELyM12C6JaaREZykKLyOrZV1JGbmUJ+Ziq5GSmIwNbKeu57fT1/etfd3W5Yz0y+MWUopxyV\nT01jiNqGMIqSmZpEZloSKcEAjaEIDaEIWyvqeO/Tnbz76U6qGkJcMXkQhfndWLe9ioVrdlBR20gw\nICQHA4zql80F4/vTu3saGcnBlsSjqtQ0hgkIpAQDBANCeW0T4YiSn5nCzppGSqsbCQYgGAgQ9HZm\n7xeV85uF6/i0rAZV6J2dxolD81BVlmwqZ0uFu0r/hMJcVm/bRVJAuOT4gYzul02f7mn0yk6jZ1Ya\nKUkBahpCrNm2i9LqRnpmp1Ja1cDG0ho2ldZQkJXKcQN7MKZfD9btqGLNtiomDMphcF4GycFAu5Jw\nfVOYsppGwmGlpLqBmoYQ2enJZKcl0T09may0ZHbVN1FR20RGSpDaxjA1DSEG5WXQIyMFVWVnTSO1\njW54+6KdtWwsrWFbZR39emRwdO9MhvXKIis1aa+dfX1TmOqGEHWNLoZ7/7meNz7ZwcDcDPIyU0lN\nCpAcDJAcFLqnJ3P+cf04cUjeQU0aqu63HFFlZ20jlbVN9M/JID2lc64z6vI+BRE5EbhDVc/2nt8G\noKo/iSqzwCuzWESSgM+BAo0TVKIkhf0RCkdoCivBgJCS1PbRYFV9Ey+t2MriDaU0hiKcNao3Z4/s\nTfeMZOqbwixaW8LHn+8iMzWJdz/dybLN5dQ2hqhv2ntM/rTkAANzM8jtlsK67dX0zE7ja6cUsqGk\nmtKqBnIzU/hoSyW76kIU5ndj6aadVNY1MWNMH5Zu2klReR1njexFSlKAj7ZUsrG0huRAgAG56SQH\nA1TVh9i+q55QZM9NIikgZKUlUV67+4rvLwzLZ8boPhSV1/Lk4s1UNbRvXHyR3cPUXz91KGP7d+eX\nf/+ET7bHGOgszjyO7pVFRHWP9w3ITWdgbgahsFIfivDRlsqWWh5AapLbodY1hqlr414eyUGhKdz2\n77RP9zR+fck4GsMRnli8mQ+KK0gKBDimdxYXTezPmm1VPL+smBMKc6luCPH3Ndv3GJZfxNUeGkOx\n77mQ1y2F8tpGInF2FVlpSWSnJe+1TkRAcDXbbZV1cecRT0pSgKSAtCSE1suJ/jwBoeUAJi05SGMo\nwo6qhj3ek5maxPnH9WXHrgYq65poCkdoDEdoCrk4d9WHSAoIaclB0pIDJAUCRFS9+N3/kaidvKrb\n6bdMZ/dzbXnf3kTcSSkpXlISoCmihMIRggEhIyUJRQmFlaZwhNtmjOCCCf1jz2wfDoWkcCEwXVW/\n7j2/AjhBVW+IKvORV6bYe77BK1Paal7XAtcCDBw4cMLmzXY7yq4QiSgNIe/H49UmcjNSOtS81PwD\naW4CawiFyUjZfZRZ1xgmOSh7Nd00hiKU1TRQVt1IfmYqBVmpBAPC1oo6ymsb6ZWdRn5makv5itpG\nln9WTnWDO9qsrg9R0xiiT/c0BuRkUF7bRGl1A+W1jYQjSs+sVI4bmMPoft1b4vzX+jI276whMzWp\nJcaahhBV9U00hpXUpAApSQHyM1MYPzCn5Wj23U93UtcUpl+PdIb1zNzjaHP7rnoWrd1BVX2ImoYw\ntU0hahpCpCYF6ZmVinqfNRSOkNMtBQG2VdZTkJVKn+7pRFQJR7w/VYb3ymJMv+4EO/AdVNY1sa2y\njm2V9WyvrGdbZT31IddUOLxnFr2y09hRVU9eZipDCrqRnZZMbWOID4srWVlcSd8e6Ywb2INlm8sp\nrWqgMexqSzUNu3fYiuL9Q1UJiDAgN4O+PdIIBgLkZaaQmZpEVX0Tu+pCVNY1sauuiay0JHK6pVDb\nGCbD26l/VlZLaU0DTSGlf046WWlJqLoTNwoLutEzK42tFXV8sr2K9TuqW2oEtU1h6hvDBALCoNwM\nemQkk5ocJD05yIlD8/bYXqLVN4V5deU2NpRUU9cUpr4pTDjiPoOIIOIST0AEwTWBBkQIeEkwZjmv\nbMCb3iPDnViyqayGitomLyFFUNxBQFIgQFiV2oYQARGSgkIwEOD8cX05YUgbF8juw6GQFC4Czm6V\nFCap6n9GlVnllYlOCpNUtc174llNwRhjOq69ScHPHqdiYEDU8/5A657TljJe81F3YKePMRljjInD\nz6SwBBgmIoUikgLMBua1KjMPuMp7fCHwz3j9CcYYY/zl2ympqhoSkRuABbhTUh9W1VUiciewVFXn\nAX8EnhCR9bgawmy/4jHGGLNvvl6noKrzgfmtpt0e9bgeuMjPGIwxxrSfXcVijDGmhSUFY4wxLSwp\nGGOMaWFJwRhjTIvDbuhsESkB9veS5nygdJ+lusahGpvF1TEWV8cdqrEdaXENUtWCfRU67JLCgRCR\npe25oq8rHKqxWVwdY3F13KEaW6LGZc1HxhhjWlhSMMYY0yLRksIDXR1AHIdqbBZXx1hcHXeoxpaQ\ncSVUn4Ixxpj4Eq2mYIwxJg5LCsYYY1okTFIQkekislZE1ovIrV0YxwAReV1E1ojIKhH5ljf9DhHZ\nIiIrvL9zuiC2TSLyobf8pd60XBH5u4is8/7P6eSYjo5aJytEZJeIfLur1peIPCwiO7y7BjZPi7mO\nxLnH2+ZWisj4To7rbhH52Fv2iyLSw5s+WETqotbd/Z0cV5vfnYjc5q2vtSJytl9xxYntmai4NonI\nCm96p6yzOPuHztvG3M2kj+w/3NDdG4AhQArwATCyi2LpA4z3HmcBnwAjgTuA/+7i9bQJyG817WfA\nrd7jW4GfdvH3+DkwqKvWF3AqMB74aF/rCDgH+CsgwGTg3U6O6ywgyXv806i4BkeX64L1FfO7834H\nHwCpQKH3mw12ZmytXv8FcHtnrrM4+4dO28YSpaYwCVivqhtVtRGYC8zqikBUdZuqLvceVwFrgH5d\nEUs7zQIe8x4/BpzfhbFMAzaoapfdpFtV32TvuwO2tY5mAY+r8w7QQ0T6dFZcqvo3VQ15T9/B3f2w\nU7WxvtoyC5irqg2q+imwHvfb7fTYRESAi4Gn/Vp+GzG1tX/otG0sUZJCP6Ao6nkxh8COWEQGA8cB\n73qTbvCqgA93djONR4G/icgyEbnWm9ZLVbeB22CBnl0QV7PZ7Pkj7er11aytdXQobXdX444omxWK\nyPsi8oaIfKEL4on13R1K6+sLwHZVXRc1rVPXWav9Q6dtY4mSFCTGtC49F1dEMoEXgG+r6i7g98BQ\nYBywDVd17Wwnq+p4YAbwTRE5tQtiiEncLV1nAs95kw6F9bUvh8R2JyLfA0LAU96kbcBAVT0OuAn4\nk4hkd2JIbX13h8T68sxhzwOQTl1nMfYPbRaNMe2A1lmiJIViYEDU8/7A1i6KBRFJxn3hT6nqnwFU\ndbuqhlU1AjyIj9XmtqjqVu//HcCLXgzbm6uj3v87Ojsuzwxguapu92Ls8vUVpa111OXbnYhcBXwR\nuEy9RmiveabMe7wM13Y/vLNiivPddfn6AhCRJODLwDPN0zpzncXaP9CJ21iiJIUlwDARKfSOOGcD\n87oiEK+t8o/AGlX9ZdT06HbALwEftX6vz3F1E5Gs5se4TsqPcOvpKq/YVcDLnRlXlD2O3Lp6fbXS\n1jqaB1zpnSEyGahsbgLoDCIyHbgFmKmqtVHTC0Qk6D0eAgwDNnZiXG19d/OA2SKSKiKFXlzvdVZc\nUc4APlbV4uYJnbXO2to/0JnbmN+96YfKH66X/hNchv9eF8ZxCq56txJY4f2dAzwBfOhNnwf06eS4\nhuDO/PgAWNW8joA84B/AOu//3C5YZxlAGdA9alqXrC9cYtoGNOGO0r7W1jrCVe3v87a5D4GJnRzX\nelx7c/N2dr9X9gLvO/4AWA6c18lxtfndAd/z1tdaYEZnf5fe9EeB61qV7ZR1Fmf/0GnbmA1zYYwx\npkWiNB8ZY4xpB0sKxhhjWlhSMMYY08KSgjHGmBaWFIwxxrSwpGBMJxKRqSLySlfHYUxbLCkYY4xp\nYUnBmBhE5HIRec8bO/8PIhIUkWoR+YWILBeRf4hIgVd2nIi8I7vvW9A81v1RIrJQRD7w3jPUm32m\niDwv7l4HT3lXsRpzSLCkYEwrIjICuAQ3QOA4IAxcBnTDjb80HngD+IH3lseBW1R1LO6q0ubpTwH3\nqeqxwEm4q2fBjXz5bdw4+UOAk33/UMa0U1JXB2DMIWgaMAFY4h3Ep+MGIIuwe5C0J4E/i0h3oIeq\nvuFNfwx4zhtHqp+qvgigqvUA3vzeU29cHXF39hoMvO3/xzJm3ywpGLM3AR5T1dv2mCjy/Vbl4o0R\nE69JqCHqcRj7HZpDiDUfGbO3fwAXikhPaLk/7iDc7+VCr8ylwNuqWgmUR9105QrgDXVj4BeLyPne\nPFJFJKNTP4Ux+8GOUIxpRVVXi8j/4u5CF8CNovlNoAYYJSLLgEpcvwO4oYzv93b6G4GvetOvAP4g\nInd687ioEz+GMfvFRkk1pp1EpFpVM7s6DmP8ZM1HxhhjWlhNwRhjTAurKRhjjGlhScEYY0wLSwrG\nGGNaWFIwxhjTwpKCMcaYFv8fkDgzVoirSpEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f53517dcf28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train loss','Val Loss'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0527581246467\n",
      "Test accuracy: 0.9924\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': [0.15704860073709861, 0.080775224628485742, 0.049936346182227136, 0.059407582717295737, 0.046045856665715111, 0.039338039717962965, 0.040020385260088366, 0.033947944030299548, 0.041011427150864622, 0.03074300321292394, 0.041529222955887964, 0.032237644835535317, 0.033452432965320258, 0.031954288615635595, 0.031445464835719028, 0.030091059081534331, 0.038502122333940313, 0.036231944926136017, 0.039205764357396401, 0.036026905714764509, 0.035273349180696092, 0.033151569459991335, 0.031766644789360546, 0.035027555194011802, 0.043584976777800877, 0.035407582562195693, 0.038199597578565225, 0.040944123070359183, 0.041409014441316595, 0.036841269980423023, 0.035652320314782902, 0.035808084855953985, 0.078454478200514127, 0.037043956092738382, 0.035743668523286712, 0.039159669361118858, 0.03992377281320323, 0.058565901803053842, 0.043354777543675484, 0.044624896139274735, 0.045288602834020454, 0.04472805690881896, 0.046074065552412412, 0.040222170172559801, 0.039916777860027286, 0.053790447260278915, 0.041294260316145755, 0.055047680183503284, 0.037852075171305843, 0.040583577382764455, 0.046065898814116372, 0.04007529662550742, 0.043611151125806283, 0.038046480043654719, 0.045328912500704518, 0.047555563160470139, 0.04724811328092865, 0.047909780889809281, 0.044952176331252397, 0.058859564303933076, 0.04476417826805127, 0.044663742571091188, 0.0437336227870459, 0.053865169356551633, 0.049247285562784876, 0.044905597002579817, 0.046326418557472791, 0.052514115379663141, 0.044305437733333841, 0.045390719590182656, 0.0431461035734058, 0.047431560644041658, 0.048371430809789402, 0.050254367352911049, 0.051388357965888372, 0.045819029940518979, 0.047658102133947521, 0.048620634298343068, 0.043670398896522966, 0.04242485619910185, 0.047384649170449031, 0.044251385525708793, 0.047855657370172777, 0.046694212576934117, 0.049353679417256532, 0.049029282017875084, 0.045454772750404118, 0.047128049157143234, 0.044691265110949459, 0.058079309059225398, 0.054070213889514003, 0.045556718435886885, 0.044059120359425837, 0.04773006137487746, 0.043918412292025096, 0.05286567612564913, 0.045944283662903672, 0.049070682835628758, 0.050705977931670261, 0.047939818345252933, 0.052269558785986284, 0.047505525137363835, 0.045166272817775556, 0.048892318028902898, 0.048928745380235887, 0.048484617736363998, 0.04674545800109281, 0.048626290409763809, 0.048558635924965982, 0.049413685983139749, 0.046843664839710621, 0.049983418152880765, 0.051953050100033579, 0.046226119100555844, 0.050146572594327248, 0.045948563694394214, 0.050903205250100655, 0.046327139712239659, 0.04969713202302764, 0.05337007175588078, 0.059645238709212615, 0.057043564214679099, 0.052094735427026174, 0.047000584007028737, 0.05730030074131473, 0.047871410714625563, 0.050284485195274009, 0.044164312902193706, 0.050006314051587016, 0.0495150221096771, 0.05156108185475141, 0.048700406254694011, 0.053028892237853141, 0.047863715471765315, 0.049602323324430111, 0.050597117445150344, 0.041870878289790109, 0.051612720072747836, 0.0455635779344786, 0.041297351080924909, 0.042382379172729724, 0.04688419584027597, 0.045706810406152723, 0.046740842998244991, 0.047397569538365499, 0.045899739184587361, 0.052482797232062513, 0.053580255662294254, 0.052205744678030533, 0.05553025686628698, 0.05531135690794263, 0.048208329427435366, 0.052261810798691112, 0.04852069438566068, 0.055290502196250146, 0.053356384537404211, 0.047883507811630442, 0.051219711598524557, 0.051620127757207139, 0.061686495933196146, 0.056229730216160533, 0.054204923665286425, 0.052201628923838235, 0.05374012108792231, 0.05432127651155224, 0.053745070070242491, 0.052705927437851095, 0.058165115746853735, 0.055655992992782469, 0.058605340188831817, 0.050051249799819474, 0.051814994976898197, 0.046957913827311223, 0.057729547025318517, 0.048610625670902026, 0.04866521823091343, 0.049613480648758375, 0.043188707243444972, 0.045999035548037227, 0.048227269870810781, 0.046063641424223804, 0.045445211344624752, 0.04675286258394408, 0.046899589128296608, 0.047000245194802025, 0.047654280386392384, 0.049131005094280408, 0.045663450520228431, 0.055824538043540359, 0.047356788065900039, 0.048990199331573787, 0.050081047443426084, 0.047065929811857039, 0.049781860728222452, 0.049126837251863981, 0.055054909533452427, 0.04945765110524853, 0.050394352475978392, 0.049607955289263102, 0.052758121167812894], 'val_acc': [0.95250000000000001, 0.97409999999999997, 0.98350000000000004, 0.98140000000000005, 0.98429999999999995, 0.98740000000000006, 0.98680000000000001, 0.98950000000000005, 0.98699999999999999, 0.99060000000000004, 0.98770000000000002, 0.98980000000000001, 0.98960000000000004, 0.98960000000000004, 0.99009999999999998, 0.99099999999999999, 0.98880000000000001, 0.98980000000000001, 0.98919999999999997, 0.99029999999999996, 0.99009999999999998, 0.99170000000000003, 0.99180000000000001, 0.99009999999999998, 0.98880000000000001, 0.99109999999999998, 0.9899, 0.99029999999999996, 0.99039999999999995, 0.99150000000000005, 0.99170000000000003, 0.99160000000000004, 0.98270000000000002, 0.99219999999999997, 0.9909, 0.99029999999999996, 0.99139999999999995, 0.98740000000000006, 0.99160000000000004, 0.99039999999999995, 0.99070000000000003, 0.99039999999999995, 0.99029999999999996, 0.99129999999999996, 0.99180000000000001, 0.98839999999999995, 0.99119999999999997, 0.98980000000000001, 0.99229999999999996, 0.99209999999999998, 0.99099999999999999, 0.99180000000000001, 0.99150000000000005, 0.9919, 0.99219999999999997, 0.99180000000000001, 0.99070000000000003, 0.99180000000000001, 0.99160000000000004, 0.98750000000000004, 0.99160000000000004, 0.99219999999999997, 0.99229999999999996, 0.99109999999999998, 0.99219999999999997, 0.99219999999999997, 0.99229999999999996, 0.99019999999999997, 0.99060000000000004, 0.99180000000000001, 0.99109999999999998, 0.99160000000000004, 0.99080000000000001, 0.99039999999999995, 0.99139999999999995, 0.99229999999999996, 0.99199999999999999, 0.99170000000000003, 0.99150000000000005, 0.9929, 0.99219999999999997, 0.99270000000000003, 0.99250000000000005, 0.99319999999999997, 0.99209999999999998, 0.99170000000000003, 0.99339999999999995, 0.99260000000000004, 0.99319999999999997, 0.99070000000000003, 0.99029999999999996, 0.9919, 0.99150000000000005, 0.9919, 0.99229999999999996, 0.99139999999999995, 0.99219999999999997, 0.99209999999999998, 0.99219999999999997, 0.99150000000000005, 0.99119999999999997, 0.99219999999999997, 0.99219999999999997, 0.9919, 0.99229999999999996, 0.99119999999999997, 0.99250000000000005, 0.99229999999999996, 0.99229999999999996, 0.99250000000000005, 0.99199999999999999, 0.99209999999999998, 0.99250000000000005, 0.9919, 0.99250000000000005, 0.99209999999999998, 0.99160000000000004, 0.99229999999999996, 0.99180000000000001, 0.99139999999999995, 0.99019999999999997, 0.99119999999999997, 0.99109999999999998, 0.99180000000000001, 0.99150000000000005, 0.99170000000000003, 0.99170000000000003, 0.99219999999999997, 0.99060000000000004, 0.99260000000000004, 0.9909, 0.99219999999999997, 0.99099999999999999, 0.99209999999999998, 0.99209999999999998, 0.99260000000000004, 0.99270000000000003, 0.99170000000000003, 0.99209999999999998, 0.99270000000000003, 0.99250000000000005, 0.99260000000000004, 0.99280000000000002, 0.99260000000000004, 0.99329999999999996, 0.99280000000000002, 0.99119999999999997, 0.9919, 0.9919, 0.99170000000000003, 0.99229999999999996, 0.99250000000000005, 0.99329999999999996, 0.99319999999999997, 0.99229999999999996, 0.99270000000000003, 0.99270000000000003, 0.9929, 0.99270000000000003, 0.99160000000000004, 0.99219999999999997, 0.99239999999999995, 0.99180000000000001, 0.99219999999999997, 0.99160000000000004, 0.99260000000000004, 0.99239999999999995, 0.9919, 0.99229999999999996, 0.99160000000000004, 0.99160000000000004, 0.99229999999999996, 0.99239999999999995, 0.99070000000000003, 0.99209999999999998, 0.99260000000000004, 0.99270000000000003, 0.99239999999999995, 0.9929, 0.99280000000000002, 0.99329999999999996, 0.99370000000000003, 0.99309999999999998, 0.99299999999999999, 0.99339999999999995, 0.99360000000000004, 0.99329999999999996, 0.99360000000000004, 0.99139999999999995, 0.99339999999999995, 0.99270000000000003, 0.99219999999999997, 0.99270000000000003, 0.99270000000000003, 0.99260000000000004, 0.99260000000000004, 0.99309999999999998, 0.99239999999999995, 0.99270000000000003, 0.99239999999999995], 'loss': [0.6897735748171806, 0.13801164129575094, 0.10081629446546236, 0.077926154278591273, 0.066501289312789841, 0.057122440733015541, 0.0500764040765663, 0.044960415629421671, 0.039257513555791226, 0.034950282789363213, 0.031564919161579261, 0.03110989635346147, 0.028203995895727228, 0.026193245188457271, 0.023957711077512552, 0.02321480423680429, 0.020044354470811473, 0.019582173383530851, 0.017325343733156719, 0.016697805578784513, 0.015196837330694931, 0.013862506270318408, 0.014693425468739588, 0.013119108050533396, 0.011904382377686852, 0.011508248200110392, 0.011182604556846975, 0.010231296125526812, 0.010114490594993307, 0.0086382743074791511, 0.0088761669117227333, 0.0084465776324951242, 0.0089401127342726497, 0.0072582390029432035, 0.0085353119929335048, 0.006534203325162768, 0.0061011834472682195, 0.0057233666773696314, 0.0057060195160122023, 0.0078296670482098617, 0.0069850719077515656, 0.0067076313355510292, 0.0069374953383051132, 0.0068741427410083517, 0.0043793759775311927, 0.0030563793489830158, 0.0047071825456258464, 0.0066360241167716287, 0.0058250637065236028, 0.0040268440912131455, 0.004459918669455146, 0.0026617105342832776, 0.0023469466825406927, 0.0022330121108710957, 0.0021549304685729263, 0.0019779629510115458, 0.0026978947129810121, 0.0034417820547852141, 0.0023530130119693848, 0.0051810012120543127, 0.0035245270657522877, 0.0041726220838336761, 0.0028329597265183567, 0.0038895494924134936, 0.002100865258409476, 0.00435728218278, 0.0019009057997558558, 0.0041597445177313907, 0.0032588809166844688, 0.0020593235368330169, 0.0029651098375616737, 0.0030383854672554208, 0.0024313939768469029, 0.0022181296345994876, 0.0015960783121194708, 0.0022441287958275399, 0.0028328702743227194, 0.0015878288715231519, 0.0020695786133576198, 0.0046381830731320106, 0.0042372363807049772, 0.0013999722575347732, 0.0011395946827994143, 0.00077953198575097908, 0.00057523147228942734, 0.0015928143115106954, 0.0010994357894564019, 0.00062491102624717318, 0.00055981408759059076, 0.0015876926134688119, 0.0061795301698856289, 0.0032362247690219193, 0.00087478833214610558, 0.0012170616360445668, 0.0013998006816896425, 0.0010994599575697673, 0.00080130155825498448, 0.00088939278689557184, 0.0011090053712826376, 0.002437449035868258, 0.0036998361063490695, 0.0011662349643338833, 0.0016037704990240248, 0.0033193883800667662, 0.0031370263931218686, 0.003145459839747582, 0.00098870895996398464, 0.00085383559450107592, 0.00075025663950452023, 0.00023989258128272013, 0.00085071647739059695, 0.00069170766998098167, 0.00054738567829981546, 0.0010863571680625075, 0.00036972289740967121, 0.0012311797378223219, 0.0012407326415008204, 0.0010182258762501382, 0.0010086545700366059, 0.0025188506036185722, 0.0066385569154540462, 0.003623451539936832, 0.0024877926346514867, 0.0033241248657603895, 0.0057014992044372471, 0.0024900583835819209, 0.0044722558546067227, 0.0021185930121136454, 0.0015555151297436472, 0.0008627526138593112, 0.0004043205296716375, 0.00075513349069853276, 0.0018446780230429794, 0.0012238446224664282, 0.0019626120249405781, 0.0028847866842356931, 0.0016650995187114707, 0.0005587609020752249, 0.0023490770152101506, 0.00085717593158841129, 0.00083852775040589524, 0.0001780511059920324, 0.00027569873673843784, 0.00016997805822340222, 7.729389449865873e-05, 5.9090120011099621e-05, 0.00011854324561832072, 0.0010112804119970103, 0.0010582068244165688, 0.0016289774729443555, 0.0012409489403899139, 0.0010173831602532421, 0.00060505507463258252, 0.0012122685547186695, 0.0009204994387977725, 0.0014323103523149409, 0.00061279603807095858, 0.00032613040887472379, 0.0010982715049654721, 0.00095614938035949607, 0.0017160289640138974, 0.0025416380852163684, 0.0015963048381244485, 0.00069901155533142779, 0.00057941736991453275, 0.00032698271262155082, 5.9968211491817175e-05, 0.00081010301981708987, 0.0011550411713918494, 0.0012038913293723453, 0.0042100271427089105, 0.0032942916054467634, 0.0030925804956200105, 0.0026359540693991373, 0.0028890374092986502, 0.00059784061780939434, 0.00034223684615315811, 0.00021469001279062923, 0.00023226267475570238, 0.00032541661789681106, 6.0905876657958893e-05, 8.1405433789465554e-05, 6.2958342387886058e-05, 3.9257500637859267e-05, 3.6581951038078843e-05, 8.589288455292869e-05, 6.6782018827476957e-05, 6.8083528837951232e-05, 8.280623989188219e-05, 0.00013700960296066569, 0.00067403475217867406, 0.0012887380364181807, 0.00041088317553179273, 0.0001111788616957862, 0.00016399201675694713, 0.00044219761221618987, 0.00037062670756252678, 8.9664934746451765e-05, 0.00029055379086429032, 0.00029840536972274093], 'acc': [0.76898333333333335, 0.95955000000000001, 0.97058333333333335, 0.97738333333333338, 0.98038333333333338, 0.98361666666666669, 0.98491666666666666, 0.98668333333333336, 0.98853333333333337, 0.98941666666666672, 0.9906166666666667, 0.9906166666666667, 0.99133333333333329, 0.99204999999999999, 0.9926666666666667, 0.99271666666666669, 0.99399999999999999, 0.99424999999999997, 0.99455000000000005, 0.995, 0.99514999999999998, 0.99580000000000002, 0.99513333333333331, 0.99601666666666666, 0.99639999999999995, 0.99653333333333338, 0.99676666666666669, 0.9967166666666667, 0.99696666666666667, 0.99731666666666663, 0.99713333333333332, 0.99724999999999997, 0.99691666666666667, 0.99770000000000003, 0.99733333333333329, 0.99796666666666667, 0.99831666666666663, 0.99808333333333332, 0.99826666666666664, 0.99751666666666672, 0.99776666666666669, 0.99793333333333334, 0.99761666666666671, 0.99781666666666669, 0.99863333333333337, 0.99911666666666665, 0.99861666666666671, 0.99786666666666668, 0.99804999999999999, 0.99885000000000002, 0.99863333333333337, 0.99918333333333331, 0.99926666666666664, 0.99921666666666664, 0.99931666666666663, 0.99944999999999995, 0.99903333333333333, 0.99909999999999999, 0.99924999999999997, 0.99838333333333329, 0.99881666666666669, 0.99851666666666672, 0.99901666666666666, 0.99890000000000001, 0.99936666666666663, 0.99876666666666669, 0.99943333333333328, 0.99865000000000004, 0.99921666666666664, 0.99926666666666664, 0.99923333333333331, 0.99909999999999999, 0.99929999999999997, 0.9992833333333333, 0.99953333333333338, 0.99934999999999996, 0.99901666666666666, 0.99943333333333328, 0.99938333333333329, 0.99883333333333335, 0.99881666666666669, 0.99958333333333338, 0.99958333333333338, 0.99976666666666669, 0.99981666666666669, 0.99946666666666661, 0.99965000000000004, 0.99980000000000002, 0.99983333333333335, 0.99948333333333328, 0.99833333333333329, 0.99903333333333333, 0.99963333333333337, 0.99956666666666671, 0.99958333333333338, 0.9997166666666667, 0.99981666666666669, 0.99965000000000004, 0.9996666666666667, 0.99950000000000006, 0.99895, 0.99973333333333336, 0.99953333333333338, 0.99904999999999999, 0.99911666666666665, 0.99924999999999997, 0.99975000000000003, 0.99975000000000003, 0.99983333333333335, 0.99995000000000001, 0.9997166666666667, 0.99983333333333335, 0.99976666666666669, 0.99965000000000004, 0.99990000000000001, 0.99968333333333337, 0.99960000000000004, 0.99970000000000003, 0.99970000000000003, 0.99934999999999996, 0.99818333333333331, 0.99890000000000001, 0.9992833333333333, 0.99890000000000001, 0.99848333333333328, 0.99931666666666663, 0.99861666666666671, 0.99921666666666664, 0.99960000000000004, 0.99970000000000003, 0.99981666666666669, 0.99975000000000003, 0.99944999999999995, 0.99956666666666671, 0.99958333333333338, 0.99918333333333331, 0.99948333333333328, 0.99988333333333335, 0.99934999999999996, 0.99963333333333337, 0.99970000000000003, 0.99996666666666667, 0.99990000000000001, 0.99995000000000001, 0.99998333333333334, 1.0, 0.99996666666666667, 0.99960000000000004, 0.99968333333333337, 0.99961666666666671, 0.99960000000000004, 0.99968333333333337, 0.99978333333333336, 0.99970000000000003, 0.99970000000000003, 0.99944999999999995, 0.99976666666666669, 0.99991666666666668, 0.99968333333333337, 0.9997166666666667, 0.99946666666666661, 0.99939999999999996, 0.9996666666666667, 0.99980000000000002, 0.99985000000000002, 0.99986666666666668, 1.0, 0.9997166666666667, 0.99960000000000004, 0.9996666666666667, 0.99886666666666668, 0.99909999999999999, 0.99924999999999997, 0.99926666666666664, 0.99926666666666664, 0.99976666666666669, 0.99988333333333335, 0.99990000000000001, 0.99993333333333334, 0.99991666666666668, 1.0, 0.99998333333333334, 1.0, 1.0, 1.0, 0.99998333333333334, 1.0, 0.99998333333333334, 0.99998333333333334, 0.99996666666666667, 0.99983333333333335, 0.9997166666666667, 0.99990000000000001, 1.0, 0.99995000000000001, 0.99990000000000001, 0.99991666666666668, 0.99998333333333334, 0.99990000000000001, 0.99990000000000001]}\n"
     ]
    }
   ],
   "source": [
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "data = pd.DataFrame(history.history)\n",
    "nome = 'DoubleConvMNISTNorm_t1' + str(datetime.datetime.now())+'.json'\n",
    "data = data.to_json()\n",
    "with open(nome, \"w+\") as output_file:\n",
    "    output_file.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
